{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1B.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Toroto006/iml2021/blob/main/task1B/Task1B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwCJDlDblbfn"
      },
      "source": [
        "### Trying to solve Task 1B now!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oehqk2wZPnlF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "trainUrl = 'https://raw.githubusercontent.com/Toroto006/iml2021/main/task1B/train.csv?token=AH44KNVSZQ2TFA45ZGBDBMDAMV2JK'\n",
        "\n",
        "#pd.set_option(\"precision\", 20)\n",
        "trainPD = pd.read_csv(trainUrl, float_precision=None)\n",
        "#trainPD"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LObH9knJ6g80"
      },
      "source": [
        "Some trying on the precision of pandas.\n",
        "Looks like the float_precision=\"high\" should be enough for this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiCh_TjH6hkI"
      },
      "source": [
        "#print(f\"precision 20: %10.8e\" % (0.43000000000000010436 - 0.43000000000000005))\n",
        "#print(f\"precision 22: %10.8e\" % (0.4300000000000001043610 - 0.43000000000000005))\n",
        "#print(f\"high precision: %10.8e and %10.8e\" % (0.42999999999999999334 - 0.43000000000000005, 0.0800000000000000016653 - 0.08000000000000007))"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBm-wbDFnJQm"
      },
      "source": [
        "Create cross validation folds:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWc8kXnZnNau"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "splits = 7\n",
        "\n",
        "X = trainPD.loc[:,'x1':'x5']\n",
        "Y = trainPD['y']\n",
        "test = {}\n",
        "train = {}\n",
        "i = 0\n",
        "# maybe use seed and random shuffle\n",
        "kf = KFold(n_splits=splits, random_state=None, shuffle=False)\n",
        "for train_index, test_index in kf.split(trainPD):\n",
        "  train[i] = (X.iloc[train_index].to_numpy(), Y.iloc[train_index].to_numpy())\n",
        "  test[i] = (X.iloc[test_index].to_numpy(), Y.iloc[test_index].to_numpy())\n",
        "  i += 1\n",
        "#test(X_test, y_test)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8Kt4ul3mJow"
      },
      "source": [
        "Creating feature set according to our exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvB4eP6GjCQG"
      },
      "source": [
        "feature_list = [lambda x: x,            # Linear\n",
        "                lambda x: np.square(x), # Quadratic \n",
        "                lambda x: np.exp(x),    # Exponential\n",
        "                lambda x: np.cos(x)]    # Cosine\n",
        "                #lambda x: 1]       # Constant\n",
        "               \n",
        "def build_features(x_train):\n",
        "    d3_phi = np.stack(tuple(feature(x_train) for feature in feature_list)) # create the feature stack\n",
        "    first4 = d3_phi.transpose(1,0,2).reshape(d3_phi.shape[1],-1) # reshape into 600, 20\n",
        "    final = np.ones((first4.shape[0],first4.shape[1]+1))  \n",
        "    final[:,:-1] = first4 # add missing constant feature by replacing all other ones with features\n",
        "    return final"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lba2GpCmQ91"
      },
      "source": [
        "# Ridge regression with small lambda still linear regression?\n",
        "def get_coefficients(x_train, y_train, lamb=1e-16):\n",
        "    phi_train = build_features(x_train)\n",
        "    dim = phi_train.shape[-1]\n",
        "    w_hat = np.dot(np.linalg.pinv(np.dot(phi_train.T, phi_train) + lamb * np.eye(dim)), \n",
        "                   np.dot(phi_train.T, y_train))\n",
        "    return w_hat"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKQLKb0amWx8"
      },
      "source": [
        "def evaluate_features(x_test, y_test, w_hat):\n",
        "    phi_test = build_features(x_test)\n",
        "    error = np.sqrt(np.power(y_test - phi_test @ w_hat, 2).mean())\n",
        "    return error "
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9ez4DfBtDtW"
      },
      "source": [
        "Try to do the evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhJwFLactGun"
      },
      "source": [
        "w_hat = get_coefficients(train[0][0], train[0][1])\n",
        "#print(w_hat)\n",
        "evalFeatures = evaluate_features(test[0][0], test[0][1], w_hat)\n",
        "# evalFeatures"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3zKw10e-xGX"
      },
      "source": [
        "Doing it by hand for one seemed like a good prediction, lets do it for all folds and see the avg error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhz6FGL1-9QY",
        "outputId": "10d518eb-81da-400e-b5e1-4d68623d8bdd"
      },
      "source": [
        "errors = []\n",
        "for i in range(0, splits):\n",
        "  w_hat = get_coefficients(train[i][0], train[i][1])\n",
        "  fold_step_err = evaluate_features(test[i][0], test[i][1], w_hat)\n",
        "  errors.append(fold_step_err)\n",
        "print(f\"Errors over folds: %s\" % errors)\n",
        "print(f\"Average error over all folds: %10.8e\" % (np.average(errors)))"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Errors over folds: [1.8471530334843937, 2.0300637018802674, 1.9766852150545569, 1.8698227492589279, 2.131994063671641, 2.8415863849203107, 2.1121027335860183]\n",
            "Average error over all folds: 2.11562970e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSC8poO7AFl4"
      },
      "source": [
        "Over the folds does not look so bad, so let's do one final train over the whole training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUKSP06_AMji"
      },
      "source": [
        "w_hat_final = get_coefficients(X.to_numpy(), Y.to_numpy())\n",
        "#w_hat_final"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-KYsO4BlqeP"
      },
      "source": [
        "Output the data for submission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvyuMd0XbWu6"
      },
      "source": [
        "res = pd.DataFrame(data=w_hat_final)\n",
        "res.to_csv(\"out.csv\", index=False, header=False, float_format='%.22f')\n",
        "#res"
      ],
      "execution_count": 187,
      "outputs": []
    }
  ]
}