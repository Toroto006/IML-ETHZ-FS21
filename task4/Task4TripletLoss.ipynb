{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwCJDlDblbfn"
   },
   "source": [
    "### Trying to solve Task 4 now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oeL297NoB-yf"
   },
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "BATCH_SIZE_IM = 16\n",
    "EMB_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.8.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.5.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn numpy matplotlib psutil pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorboard_plugin_profile in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (56.2.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (3.17.0)\n",
      "Requirement already satisfied, skipping upgrade: gviz-api>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from werkzeug>=0.11.15->tensorboard_plugin_profile) (0.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorboard_plugin_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-db56aae9b963f2dc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-db56aae9b963f2dc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/ --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "oehqk2wZPnlF",
    "outputId": "42abd04d-aed9-4c82-9bfa-55ead3b93fd7"
   },
   "outputs": [],
   "source": [
    "# run for a remote notebook: docker run -it --gpus all -v /root/iml2021/task4:/tf/task4 -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter\n",
    "# need stuff cd /task4 && python -m pip install sklearn numpy matplotlib psutil pandas && python3 task4.py\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "#from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Concatenate, Lambda, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from lru_cache_memory_aware import lru_cache\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW_pdKJmXr1R"
   },
   "source": [
    "Following is the example by keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cSG9RinbUd5M"
   },
   "outputs": [],
   "source": [
    "# TODO https://keras.io/api/applications/resnet/ use ResNet50v2 and then one last time ResNet152v2\n",
    "def example():\n",
    "  model = ResNet50(\n",
    "      include_top=True,\n",
    "      weights=\"imagenet\",\n",
    "      input_tensor=None,\n",
    "      input_shape=None,\n",
    "      pooling=None,\n",
    "      classes=1000,\n",
    "      classifier_activation=\"softmax\",\n",
    "  )\n",
    "  img_path = 'food/00000.jpg'\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "\n",
    "  preds = model.predict(x)\n",
    "  # decode the results into a list of tuples (class, description, probability)\n",
    "  # (one such list for each sample in the batch)\n",
    "  print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MwoeX2dz9hu-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip -o food.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPD = pd.read_csv(\"train_triplets.txt\", header=None, delimiter=' ')\n",
    "testPD = pd.read_csv(\"test_triplets.txt\", header=None, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623</td>\n",
       "      <td>1263</td>\n",
       "      <td>4221</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2841</td>\n",
       "      <td>4262</td>\n",
       "      <td>3258</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3453</td>\n",
       "      <td>1963</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1205</td>\n",
       "      <td>3519</td>\n",
       "      <td>4785</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3427</td>\n",
       "      <td>2101</td>\n",
       "      <td>2799</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119025</th>\n",
       "      <td>1431</td>\n",
       "      <td>1397</td>\n",
       "      <td>3914</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119026</th>\n",
       "      <td>1044</td>\n",
       "      <td>1728</td>\n",
       "      <td>3374</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119027</th>\n",
       "      <td>2832</td>\n",
       "      <td>1682</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119028</th>\n",
       "      <td>2864</td>\n",
       "      <td>3614</td>\n",
       "      <td>2252</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119029</th>\n",
       "      <td>1201</td>\n",
       "      <td>4875</td>\n",
       "      <td>3612</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119030 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y\n",
       "0       1623  1263  4221  1.0\n",
       "1       2841  4262  3258  1.0\n",
       "2          2  3453  1963  1.0\n",
       "3       1205  3519  4785  1.0\n",
       "4       3427  2101  2799  1.0\n",
       "...      ...   ...   ...  ...\n",
       "119025  1431  1397  3914  1.0\n",
       "119026  1044  1728  3374  1.0\n",
       "119027  2832  1682    26  1.0\n",
       "119028  2864  3614  2252  1.0\n",
       "119029  1201  4875  3612  1.0\n",
       "\n",
       "[119030 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the y lable, where 1 means exactly what the exercise defines,\n",
    "# i.e. 0 is closer in taste to 1 than 2\n",
    "trainPD['y'] = pd.DataFrame(np.ones((trainPD.shape[0],1)), columns=[\"y\"])\n",
    "trainPD.columns = ['A', 'B', 'C', 'y']\n",
    "trainPD = trainPD.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "trainPDreverseF = trainPD.copy()\n",
    "trainPDreverseF[\"A\"] = trainPD[\"B\"].copy()\n",
    "trainPDreverseF[\"B\"] = trainPD[\"A\"].copy()\n",
    "trainPD = trainPD.append(trainPDreverseF).reset_index(drop=True)\n",
    "trainPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJddS7B4ui7F"
   },
   "source": [
    "Prepare the data splits  \n",
    "TODO: create the generator with turning and then combine the correct 3 always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "wFOw0IBJt6aa",
    "outputId": "acd9c173-80d6-4bcd-d767-b0e0ab4d105f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113078, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88856</th>\n",
       "      <td>4621</td>\n",
       "      <td>1127</td>\n",
       "      <td>2103</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79169</th>\n",
       "      <td>824</td>\n",
       "      <td>2817</td>\n",
       "      <td>4313</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A     B     C    y\n",
       "88856  4621  1127  2103  1.0\n",
       "79169   824  2817  4313  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split picture combinations\n",
    "def createTrainSplit(df):\n",
    "  global train_split, test_split, val_split\n",
    "  train_split, test_split = train_test_split(df, test_size=0.05, random_state=random_state)\n",
    "  #train_split, val_split = train_test_split(train_split, test_size=0.2, random_state=random_state)\n",
    "\n",
    "createTrainSplit(trainPD)\n",
    "print(train_split.shape)\n",
    "train_split.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FDsZxP7E0rH"
   },
   "source": [
    "Let's do the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "joY6BRUTEz3m"
   },
   "outputs": [],
   "source": [
    "# TODO maybe think if actually using resnet preprocess_input is ok\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCBINL80LUgK"
   },
   "source": [
    "We have to write our own generator because of the different input... [example](https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7eq6Zs-vCZBg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "      <th>transform_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4621</td>\n",
       "      <td>1127</td>\n",
       "      <td>2103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4621</td>\n",
       "      <td>1127</td>\n",
       "      <td>2103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>824</td>\n",
       "      <td>2817</td>\n",
       "      <td>4313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>824</td>\n",
       "      <td>2817</td>\n",
       "      <td>4313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3944</td>\n",
       "      <td>2551</td>\n",
       "      <td>2138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226151</th>\n",
       "      <td>2008</td>\n",
       "      <td>3248</td>\n",
       "      <td>3619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226152</th>\n",
       "      <td>2534</td>\n",
       "      <td>3256</td>\n",
       "      <td>4272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226153</th>\n",
       "      <td>2534</td>\n",
       "      <td>3256</td>\n",
       "      <td>4272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226154</th>\n",
       "      <td>2285</td>\n",
       "      <td>1466</td>\n",
       "      <td>306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226155</th>\n",
       "      <td>2285</td>\n",
       "      <td>1466</td>\n",
       "      <td>306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226156 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y  transform_n\n",
       "0       4621  1127  2103  1.0            0\n",
       "1       4621  1127  2103  1.0            1\n",
       "2        824  2817  4313  1.0            0\n",
       "3        824  2817  4313  1.0            1\n",
       "4       3944  2551  2138  1.0            0\n",
       "...      ...   ...   ...  ...          ...\n",
       "226151  2008  3248  3619  1.0            1\n",
       "226152  2534  3256  4272  1.0            0\n",
       "226153  2534  3256  4272  1.0            1\n",
       "226154  2285  1466   306  1.0            0\n",
       "226155  2285  1466   306  1.0            1\n",
       "\n",
       "[226156 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply_df(amount, df:pd.DataFrame):\n",
    "  ret = df.copy()\n",
    "  ret = ret.apply(lambda row: row.loc[row.index.repeat(amount)], axis=0).reset_index(drop=True)\n",
    "  # now add the transform_n just to see in index afterwards\n",
    "  ns = np.concatenate(list(itertools.repeat(np.arange(0,amount), df.shape[0])))\n",
    "  ret[\"transform_n\"] = pd.DataFrame(ns,columns=[\"transform_n\"])\n",
    "  return ret\n",
    "\n",
    "multiply_df(2, train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "x77kcv4UFz1e"
   },
   "outputs": [],
   "source": [
    "def show_images(images: [np.ndarray]) -> None:\n",
    "    n: int = len(images)\n",
    "    f = plt.figure()\n",
    "    for i in range(n):\n",
    "        # Debug, plot figure\n",
    "        f.add_subplot(1, n, i + 1)\n",
    "        plt.imshow(image.array_to_img(images[i]))\n",
    "\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_index):\n",
    "    path = f\"food/{str(image_index).zfill(5)}.jpg\"\n",
    "    h, w, = (224, 224)\n",
    "    img = image.load_img(path, target_size=(h, w))\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the images into memory, as we then are quicker to load them when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "imageDict = {}\n",
    "for i in range(0, 10000):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    imageDict[i] = load_image(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y1VoR1bkLfGU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class task4DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "  def __init__(self, df,\n",
    "                batch_size=1024,\n",
    "                input_size=(224, 224, 3),\n",
    "                augmenter:ImageDataGenerator=None,\n",
    "                shuffle=False,\n",
    "                seed=42,\n",
    "                amount_augmented=2,\n",
    "                do_multiply=False,\n",
    "                do_augment=False,\n",
    "                ret_labels=True,\n",
    "                random=False\n",
    "               ):\n",
    "        \n",
    "    self.df = multiply_df(amount_augmented, df) if do_multiply else df\n",
    "    self.batch_size = batch_size\n",
    "    self.input_size = input_size\n",
    "    self.shuffle = shuffle\n",
    "    self.seed = seed\n",
    "    self.do_augment = do_augment\n",
    "    self.augmenter:ImageDataGenerator = augmenter\n",
    "    self.amount_augmented = amount_augmented\n",
    "    self.ret_labels = ret_labels\n",
    "    self.random = random\n",
    "\n",
    "    self.n = len(self.df)\n",
    "\n",
    "  # GB = 1024**3\n",
    "  #@lru_cache(use_memory_up_to=(leave_free_GB * 1024**3))\n",
    "  #def __load_image(self, image_index):\n",
    "  #  path = f\"food/{str(image_index).zfill(5)}.jpg\"\n",
    "  #  h, w, chann = self.input_size\n",
    "  #  img = image.load_img(path, target_size=(h, w))\n",
    "  #  img = image.img_to_array(img)\n",
    "  #  return img\n",
    "\n",
    "  def __get_image_batch(self, img_indices):\n",
    "    batch = [imageDict[x] for _, x in img_indices.iteritems()]\n",
    "    batch = np.stack( batch, axis=0 )\n",
    "    return batch\n",
    "\n",
    "  def __get_transform(self, img_batch):\n",
    "    # returns the transformed img_batch if augmenter defined\n",
    "    # TODO check if the random_transform returns a copy or else \n",
    "    # use https://stackoverflow.com/questions/54909357/how-to-get-functools-lru-cache-to-return-new-instances\n",
    "    # to return copy of load_img\n",
    "    # TODO self seed probably does not do it here! , seed=self.seed\n",
    "    #img_batch = [self.augmenter.random_transform(img, seed=self.seed) for img in img_batch], axis=0 )\n",
    "    if self.do_augment:\n",
    "    #    img_batch = pool.map(self.augmenter.random_transform, img_batch)\n",
    "    #    img_batch = np.stack(img_batch, axis=0)\n",
    "        for i, img in enumerate(img_batch):\n",
    "            img_batch[i] = self.augmenter.random_transform(img, seed=self.seed)\n",
    "    img_batch = self.augmenter.standardize(img_batch)\n",
    "    return img_batch\n",
    "\n",
    "  def __get_data(self, batch_df):\n",
    "    \n",
    "    # batch_df is of form [A, B, C, y, transform_n] x n\n",
    "    batch_A = self.__get_image_batch(batch_df['A'])\n",
    "    batch_B = self.__get_image_batch(batch_df['B'])\n",
    "    batch_C = self.__get_image_batch(batch_df['C'])\n",
    "    #show_images(batch_A)\n",
    "    batch_A = self.__get_transform(batch_A)\n",
    "    #show_images(batch_A)\n",
    "    batch_B = self.__get_transform(batch_B)\n",
    "    batch_C = self.__get_transform(batch_C)\n",
    "    X = [batch_A, batch_B, batch_C]\n",
    "    y = batch_df['y'].to_numpy() if self.ret_labels else []\n",
    "    y = y if not self.random else np.random.randint(1, size=(1,3,batch_df.shape[0])).T\n",
    "    return X, y\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    if self.shuffle:\n",
    "      self.df = self.df.sample(frac=1, random_state=self.seed).reset_index(drop=True)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "    X, y = self.__get_data(batches)\n",
    "    return X, y\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.n // self.batch_size\n",
    "\n",
    "testDG = task4DataGenerator(train_split, batch_size=2, augmenter=trainAug)\n",
    "X, y = testDG[0]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HwIijdHWBuIi"
   },
   "outputs": [],
   "source": [
    "trainGN = task4DataGenerator(train_split, do_augment=True, do_multiply=True, \n",
    "                             augmenter=trainAug, batch_size=BATCH_SIZE_IM,\n",
    "                            shuffle=True, random=True)\n",
    "valGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE_IM, random=True)\n",
    "# let's use the public score as test actually\n",
    "#testGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_reversed = train_split.copy()\n",
    "train_split_reversed[\"A\"] = train_split[\"B\"].copy()\n",
    "train_split_reversed[\"B\"] = train_split[\"A\"].copy()\n",
    "trainGNrev = task4DataGenerator(train_split_reversed, do_augment=True, do_multiply=True, \n",
    "                             augmenter=trainAug, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ6SEW3LyRdg"
   },
   "source": [
    "Let's try to follow [this](https://www.pyimagesearch.com/2020/04/27/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning/) example and [this](https://github.com/noelcodella/tripletloss-keras-tensorflow/blob/master/tripletloss.py) for triplet loss for a bit in regards to fine tuning the ResNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(_, y_pred):\n",
    "    #print(y_pred.shape)\n",
    "    margin = K.constant(1)\n",
    "    return K.mean(K.maximum(K.constant(0), K.square(y_pred[:,0,0]) - 0.5*(K.square(y_pred[:,1,0])+K.square(y_pred[:,2,0])) + margin))\n",
    "\n",
    "def accuracy(_, y_pred):\n",
    "    #print(y_true.shape)\n",
    "    return K.mean(y_pred[:,0,0] < y_pred[:,1,0])\n",
    "\n",
    "def l2Norm(x):\n",
    "    return  K.l2_normalize(x, axis=-1)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hPuVKCpbAH5S"
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "#tboard_callback = keras.callbacks.TensorBoard(log_dir = logs, update_freq=50)\n",
    "tboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir = logs,\n",
    "    histogram_freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripletCheckpoint_filepath = 'tripletCheckpoint_new/'\n",
    "model_tripletCheckpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=tripletCheckpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(emb_size):\n",
    "    input_shape=(224, 224, 3)\n",
    "    \n",
    "    # Initialize a ResNet50_ImageNet Model\n",
    "    resnet_input = Input(shape=input_shape)\n",
    "    resnet_model = keras.applications.resnet50.ResNet50(weights='imagenet', include_top = False, input_tensor=resnet_input)\n",
    "\n",
    "    # New Layers over ResNet50\n",
    "    net = resnet_model.output\n",
    "    #net = kl.Flatten(name='flatten')(net)\n",
    "    net = GlobalAveragePooling2D(name='gap')(net)\n",
    "    #net = kl.Dropout(0.5)(net)\n",
    "    net = Dense(emb_size,activation='relu',name='t_emb_1')(net)\n",
    "    net = Lambda(lambda  x: K.l2_normalize(x,axis=1), name='t_emb_1_l2norm')(net)\n",
    "\n",
    "    # model creation\n",
    "    base_model = Model(resnet_model.input, net, name=\"base_model\")\n",
    "\n",
    "    # triplet framework, shared weights\n",
    "    input_anchor = Input(shape=input_shape, name='input_anchor')\n",
    "    input_positive = Input(shape=input_shape, name='input_pos')\n",
    "    input_negative = Input(shape=input_shape, name='input_neg')\n",
    "\n",
    "    net_anchor = base_model(input_anchor)\n",
    "    net_positive = base_model(input_positive)\n",
    "    net_negative = base_model(input_negative)\n",
    "\n",
    "    # The Lamda layer produces output using given function. Here its Euclidean distance.\n",
    "    positive_dist = Lambda(euclidean_distance, name='pos_dist')([net_anchor, net_positive])\n",
    "    negative_dist = Lambda(euclidean_distance, name='neg_dist')([net_anchor, net_negative])\n",
    "    tertiary_dist = Lambda(euclidean_distance, name='ter_dist')([net_positive, net_negative])\n",
    "\n",
    "    # This lambda layer simply stacks outputs so both distances are available to the objective\n",
    "    stacked_dists = Lambda(lambda vects: K.stack(vects, axis=1), name='stacked_dists')([positive_dist, negative_dist, tertiary_dist])\n",
    "\n",
    "    model = Model([input_anchor, input_positive, input_negative], stacked_dists, name='triple_siamese')\n",
    "\n",
    "    base_lr = 0.0001\n",
    "    momentum = 0.9\n",
    "    model.compile(\n",
    "      #optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      optimizer=keras.optimizers.SGD(learning_rate=base_lr, momentum=momentum, nesterov=False, name=\"SGD\"),\n",
    "      loss=triplet_loss,\n",
    "      metrics=[accuracy])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "TMyNuFaxg54M",
    "outputId": "9f5cc07f-7cb9-495f-8a29-adae0e7a2da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"triple_siamese\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_anchor (InputLayer)       [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_pos (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_neg (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         (None, 512)          24636800    input_anchor[0][0]               \n",
      "                                                                 input_pos[0][0]                  \n",
      "                                                                 input_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pos_dist (Lambda)               (None, 1)            0           base_model[0][0]                 \n",
      "                                                                 base_model[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "neg_dist (Lambda)               (None, 1)            0           base_model[0][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ter_dist (Lambda)               (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "stacked_dists (Lambda)          (None, 3, 1)         0           pos_dist[0][0]                   \n",
      "                                                                 neg_dist[0][0]                   \n",
      "                                                                 ter_dist[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,636,800\n",
      "Trainable params: 24,583,680\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "createModel(EMB_SIZE).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28269/28269 [==============================] - 5293s 187ms/step - loss: 0.7130 - accuracy: 0.6942 - val_loss: 0.7038 - val_accuracy: 0.6946\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69456, saving model to tripletCheckpoint_new/\n",
      "Done fitting\n"
     ]
    }
   ],
   "source": [
    "model = createModel(EMB_SIZE)\n",
    "#model.load_weights(tripletCheckpoint_filepath)\n",
    "print(\"Starting to fit\")\n",
    "fitted = model.fit(\n",
    "    trainGN,\n",
    "    batch_size=BATCH_SIZE_IM,\n",
    "    epochs=1,\n",
    "    callbacks=[early_stopping, tboard_callback, model_tripletCheckpoint_callback],\n",
    "    validation_data=valGN,\n",
    "    use_multiprocessing = True,\n",
    "    workers=8,\n",
    "    verbose=1)\n",
    "print(\"Done fitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model ...\n"
     ]
    }
   ],
   "source": [
    "print('Saving model ...')\n",
    "output = \"embeddingFinal\"\n",
    "\n",
    "# Save the model and weights\n",
    "model.save(f'{output}.h5')\n",
    "\n",
    "# Due to some remaining Keras bugs around loading custom optimizers\n",
    "# and objectives, we save the model architecture as well\n",
    "model_json = model.to_json()\n",
    "with open(f'{output}.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we now have the \"trained\" embedding, let's try a Ridge regression onto the labels we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBaseModelFromFile(path):\n",
    "    with open(path + '.json', \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "\n",
    "        loaded_model = keras.models.model_from_json(model_json)\n",
    "        loaded_model.load_weights(path + '.h5')\n",
    "        return loaded_model.get_layer('base_model')\n",
    "\n",
    "#baseModel = loadBaseModelFromFile(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(base_model_path=\"embeddingFinal\", metrics=METRICS):\n",
    "    #baseModel = None\n",
    "    base_model = loadBaseModelFromFile(base_model_path)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    input_A = Input(shape=(224, 224, 3), name='input_A')\n",
    "    input_B = Input(shape=(224, 224, 3), name='input_B')\n",
    "    input_C = Input(shape=(224, 224, 3), name='input_C')\n",
    "\n",
    "    # create a new model without the triple loss\n",
    "    model_A = base_model(input_A)\n",
    "    model_B = base_model(input_B)\n",
    "    model_C = base_model(input_C)\n",
    "    #model = Model(input_single, net_single, name='embedding_net')\n",
    "\n",
    "   \n",
    "\n",
    "    # we use 3 times base model to get the features from the 3 images combined\n",
    "    concat = Concatenate()([model_A, model_B, model_C])\n",
    "    headModel = Dropout(0.5)(concat)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.5)(headModel)\n",
    "    headModel = Dense(1, activation='sigmoid')(headModel)\n",
    "    model = Model(inputs=[input_A, input_B, input_C], outputs=[headModel], name=\"classifier_net\")\n",
    "\n",
    "    # actually compile it now\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.binary_crossentropy,\n",
    "      metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classifier_net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_A (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_B (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_C (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         (None, 512)          24636800    input_A[0][0]                    \n",
      "                                                                 input_B[0][0]                    \n",
      "                                                                 input_C[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1536)         0           base_model[3][0]                 \n",
      "                                                                 base_model[4][0]                 \n",
      "                                                                 base_model[5][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1536)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          393472      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,096,321\n",
      "Trainable params: 459,521\n",
      "Non-trainable params: 24,636,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "make_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoint_model3/'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2762</td>\n",
       "      <td>3127</td>\n",
       "      <td>1659</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1531</td>\n",
       "      <td>62</td>\n",
       "      <td>3849</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1514</td>\n",
       "      <td>1885</td>\n",
       "      <td>373</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601</td>\n",
       "      <td>4295</td>\n",
       "      <td>845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1306</td>\n",
       "      <td>3411</td>\n",
       "      <td>4212</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238055</th>\n",
       "      <td>3177</td>\n",
       "      <td>1791</td>\n",
       "      <td>1130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238056</th>\n",
       "      <td>714</td>\n",
       "      <td>1913</td>\n",
       "      <td>3094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238057</th>\n",
       "      <td>2801</td>\n",
       "      <td>62</td>\n",
       "      <td>1828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238058</th>\n",
       "      <td>709</td>\n",
       "      <td>1363</td>\n",
       "      <td>1010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238059</th>\n",
       "      <td>4385</td>\n",
       "      <td>665</td>\n",
       "      <td>966</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y\n",
       "0       2762  3127  1659  0.0\n",
       "1       1531    62  3849  1.0\n",
       "2       1514  1885   373  1.0\n",
       "3       2601  4295   845  1.0\n",
       "4       1306  3411  4212  1.0\n",
       "...      ...   ...   ...  ...\n",
       "238055  3177  1791  1130  1.0\n",
       "238056   714  1913  3094  0.0\n",
       "238057  2801    62  1828  1.0\n",
       "238058   709  1363  1010  1.0\n",
       "238059  4385   665   966  1.0\n",
       "\n",
       "[238060 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPD = pd.read_csv(\"train_triplets.txt\", header=None, delimiter=' ')\n",
    "# Add the y lable, where 1 means exactly what the exercise defines,\n",
    "# i.e. 0 is closer in taste to 1 than 2\n",
    "trainPDreverse = trainPD.copy()\n",
    "trainPDreverse[1] = trainPD[2].copy()\n",
    "trainPDreverse[2] = trainPD[1].copy()\n",
    "trainPD['y'] = pd.DataFrame(np.ones((trainPD.shape[0],1)), columns=[\"y\"])\n",
    "trainPDreverse['y'] = pd.DataFrame(np.zeros((trainPDreverse.shape[0],1)), columns=[\"y\"])\n",
    "trainPD = trainPD.append(trainPDreverse).reset_index(drop=True)\n",
    "# move B to A -> same lable, but a should make for more diverse input with same idea behind it\n",
    "trainPDreverseF = trainPD.copy()\n",
    "trainPDreverseF[0] = trainPD[1].copy()\n",
    "trainPDreverseF[1] = trainPD[0].copy()\n",
    "trainPD = trainPD.append(trainPDreverseF).reset_index(drop=True)\n",
    "# Give labels and reshuffle\n",
    "trainPD.columns = ['A', 'B', 'C', 'y']\n",
    "trainPD = trainPD.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "trainPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "createTrainSplit(trainPD)\n",
    "trainGN = task4DataGenerator(train_split, do_augment=True, \n",
    "                             augmenter=trainAug, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "valGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model\n",
      "Starting to fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1766/1766 [==============================] - 1724s 968ms/step - loss: 0.5367 - tp: 77403.0000 - fp: 25234.0000 - tn: 87789.0000 - fn: 35622.0000 - accuracy: 0.7308 - precision: 0.7541 - recall: 0.6848 - auc: 0.8051 - prc: 0.8103 - val_loss: 0.5648 - val_tp: 3439.0000 - val_fp: 1037.0000 - val_tn: 4864.0000 - val_fn: 2436.0000 - val_accuracy: 0.7051 - val_precision: 0.7683 - val_recall: 0.5854 - val_auc: 0.7806 - val_prc: 0.7843\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70508, saving model to checkpoint_model3/\n",
      "Epoch 2/2\n",
      "1766/1766 [==============================] - 1703s 961ms/step - loss: 0.5141 - tp: 80241.0000 - fp: 23888.0000 - tn: 89131.0000 - fn: 32788.0000 - accuracy: 0.7493 - precision: 0.7706 - recall: 0.7099 - auc: 0.8245 - prc: 0.8292 - val_loss: 0.5581 - val_tp: 3707.0000 - val_fp: 1236.0000 - val_tn: 4665.0000 - val_fn: 2168.0000 - val_accuracy: 0.7109 - val_precision: 0.7499 - val_recall: 0.6310 - val_auc: 0.7843 - val_prc: 0.7890\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70508 to 0.71094, saving model to checkpoint_model3/\n",
      "Done fitting\n"
     ]
    }
   ],
   "source": [
    "print(\"Making model\")\n",
    "model = make_model()\n",
    "#model.load_weights(checkpoint_filepath)\n",
    "print(\"Starting to fit\")\n",
    "model = model.fit(\n",
    "    trainGN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=2,\n",
    "    callbacks=[early_stopping, tboard_callback, model_checkpoint_callback],\n",
    "    validation_data=valGN,\n",
    "    #use_multiprocessing = True,\n",
    "    workers=6,\n",
    "    verbose=1)\n",
    "print(\"Done fitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually create the output for the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9896</td>\n",
       "      <td>9640</td>\n",
       "      <td>9177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6592</td>\n",
       "      <td>9283</td>\n",
       "      <td>7104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8655</td>\n",
       "      <td>6174</td>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9223</td>\n",
       "      <td>8187</td>\n",
       "      <td>8678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7317</td>\n",
       "      <td>5392</td>\n",
       "      <td>9470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59539</th>\n",
       "      <td>6113</td>\n",
       "      <td>8042</td>\n",
       "      <td>6277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59540</th>\n",
       "      <td>8851</td>\n",
       "      <td>6075</td>\n",
       "      <td>8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59541</th>\n",
       "      <td>6299</td>\n",
       "      <td>7843</td>\n",
       "      <td>7940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59542</th>\n",
       "      <td>7652</td>\n",
       "      <td>5620</td>\n",
       "      <td>5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59543</th>\n",
       "      <td>8475</td>\n",
       "      <td>6082</td>\n",
       "      <td>9044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59544 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          A     B     C\n",
       "0      9896  9640  9177\n",
       "1      6592  9283  7104\n",
       "2      8655  6174  6400\n",
       "3      9223  8187  8678\n",
       "4      7317  5392  9470\n",
       "...     ...   ...   ...\n",
       "59539  6113  8042  6277\n",
       "59540  8851  6075  8549\n",
       "59541  6299  7843  7940\n",
       "59542  7652  5620  5416\n",
       "59543  8475  6082  9044\n",
       "\n",
       "[59544 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPD.columns = ['A', 'B', 'C']\n",
    "submissionGN = task4DataGenerator(testPD, augmenter=valAug, batch_size=8, ret_labels=False)\n",
    "testPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2594d8cb70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = make_model()\n",
    "test.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7443/7443 [==============================] - 392s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "res = test.predict(submissionGN, verbose=1, use_multiprocessing=True, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.419134    10\n",
       "0.162725     6\n",
       "0.092621     5\n",
       "0.223720     4\n",
       "0.919867     4\n",
       "            ..\n",
       "0.579191     1\n",
       "0.579181     1\n",
       "0.579175     1\n",
       "0.579145     1\n",
       "0.032039     1\n",
       "Length: 59236, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res)\n",
    "res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not look too bad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change shape and threshold to 0 1 for submission\n",
      "(59544,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59539</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59540</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59541</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59542</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59543</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59544 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "...   ..\n",
       "59539  0\n",
       "59540  0\n",
       "59541  1\n",
       "59542  1\n",
       "59543  0\n",
       "\n",
       "[59544 rows x 1 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Change shape and threshold to 0 1 for submission')\n",
    "seq_predictions=np.transpose(res.to_numpy())[0]  # transformation to get (n,)\n",
    "print(seq_predictions.shape)  # now the shape is (n,)\n",
    "# Applying transformation to get binary values predictions with 0.5 as thresold\n",
    "seq_predictions = list(map(lambda x: 0 if x<0.5 else 1, seq_predictions))\n",
    "seq_predictions = pd.DataFrame(seq_predictions)\n",
    "seq_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "vvyuMd0XbWu6"
   },
   "outputs": [],
   "source": [
    "seq_predictions.to_csv(\"outTry2.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQLKF5XjVpfGVnyYGIq1JW",
   "name": "Task4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
