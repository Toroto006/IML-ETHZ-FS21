# -*- coding: utf-8 -*-
"""Task4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Toroto006/iml2021/blob/main/task4/Task4.ipynb

### Trying to solve Task 4 now!
"""

random_state = 42
EPOCHS = 100
BATCH_SIZE = 1024
leave_free_GB = 0.4

# need stuff python -m pip install sklearn numpy matplotlib psutil pandas
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Concatenate
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow import keras

import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
import os
import itertools
import matplotlib.pyplot as plt
from lru_cache_memory_aware import lru_cache

# TODO https://keras.io/api/applications/resnet/ use ResNet50v2 and then one last time ResNet152v2
model = ResNet50(
    include_top=True,
    weights="imagenet",
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation="softmax",
)

"""Following is the example by keras."""

img_path = 'food/00000.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

preds = model.predict(x)
# decode the results into a list of tuples (class, description, probability)
# (one such list for each sample in the batch)
print('Predicted:', decode_predictions(preds, top=3)[0])

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !unzip food.zip

trainPD = pd.read_csv("train_triplets.txt", header=None, delimiter=' ')
testPD = pd.read_csv("test_triplets.txt", header=None, delimiter=' ')

# Add the y lable, where 1 means exactly what the exercise defines,
# i.e. 0 is closer in taste to 1 than 2
trainPDreverse = trainPD.copy()
trainPDreverse[1] = trainPD[2].copy()
trainPDreverse[2] = trainPD[1].copy()
trainPD['y'] = pd.DataFrame(np.ones((trainPD.shape[0],1)), columns=["y"])
trainPDreverse['y'] = pd.DataFrame(np.zeros((trainPDreverse.shape[0],1)), columns=["y"])
trainPD = trainPD.append(trainPDreverse).reset_index(drop=True)
trainPD.columns = ['A', 'B', 'C', 'y']
trainPD.head(2)

"""Prepare the data splits  
TODO: create the generator with turning and then combine the correct 3 always.
"""

# split picture combinations
def createTrainSplit(df):
  global train_split, test_split, val_split
  train_split, test_split = train_test_split(df, test_size=0.15, random_state=random_state)
  train_split, val_split = train_test_split(train_split, test_size=0.1, random_state=random_state)

createTrainSplit(trainPD)
print(train_split.shape)
train_split.head(2)

# testing the multiply_df as it is a bit more complex
def multiply_df(df:pd.DataFrame):
  ret = df.copy()
  ret = ret.apply(lambda row: row.loc[row.index.repeat(10)], axis=0).reset_index(drop=True)
  # now add the transform_n just to see in index afterwards
  ret["transform_n"] = pd.DataFrame(np.concatenate(list(itertools.repeat(np.arange(0,10), df.shape[0]))),columns=["transform_n"])
  return ret

multiply_df(train_split)

"""Let's do the preprocessing"""

# TODO maybe think if actually using resnet preprocess_input is ok
trainAug = ImageDataGenerator(
	rotation_range=25,
	zoom_range=0.1,
	width_shift_range=0.1,
	height_shift_range=0.1,
	shear_range=0.2,
	horizontal_flip=True,
	fill_mode="nearest",
  preprocessing_function=preprocess_input)

# initialize the validation/testing data augmentation object (which
# we'll be adding mean subtraction to)
valAug = ImageDataGenerator(preprocessing_function=preprocess_input)

"""SHIT we have to write our own generator because of the different input... [example](https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3)"""

def multiply_df(amount, df:pd.DataFrame):
  ret = df.copy()
  ret = ret.apply(lambda row: row.loc[row.index.repeat(amount)], axis=0).reset_index(drop=True)
  # now add the transform_n just to see in index afterwards
  ns = np.concatenate(list(itertools.repeat(np.arange(0,amount), df.shape[0])))
  ret["transform_n"] = pd.DataFrame(ns,columns=["transform_n"])
  return ret

def show_images(images: [np.ndarray]) -> None:
    n: int = len(images)
    f = plt.figure()
    for i in range(n):
        # Debug, plot figure
        f.add_subplot(1, n, i + 1)
        plt.imshow(image.array_to_img(images[i]))

    plt.show(block=True)

class task4DataGenerator(keras.utils.Sequence):

  def __init__(self, df,
                batch_size=1024,
                input_size=(224, 224, 3),
                augmenter:ImageDataGenerator=None,
                shuffle=True,
                seed=42,
                amount_augmented=3,
                do_multiply=False
               ):
        
    self.df = multiply_df(amount_augmented, df) if do_multiply else df
    self.batch_size = batch_size
    self.input_size = input_size
    self.shuffle = shuffle
    self.seed = seed
    self.augmenter:ImageDataGenerator = augmenter
    self.amount_augmented = amount_augmented

    self.n = len(self.df)

  # GB = 1024**3
  @lru_cache(use_memory_up_to=(leave_free_GB * 1024**3))
  def __load_image(self, image_index):
    path = f"food/{str(image_index).zfill(5)}.jpg"
    h, w, chann = self.input_size
    img = image.load_img(path, target_size=(h, w))
    img = image.img_to_array(img)
    return img

  def __get_image_batch(self, img_indices):
    batch = np.zeros(img_indices.shape + self.input_size)
    i:Int = 0
    for _, img_index in img_indices.iteritems():
      batch[i] = self.__load_image(img_index)
      i += 1
    return batch

  def __get_transform(self, img_batch):
    # returns the transformed img_batch if augmenter defined
    # TODO For performance remove this if
    if self.augmenter is None:
      return img_batch
    # TODO check if the random_transform returns a copy or else 
    # use https://stackoverflow.com/questions/54909357/how-to-get-functools-lru-cache-to-return-new-instances
    # to return copy of load_img
    # TODO self seed probably does not do it here! , seed=self.seed
    for id, img in enumerate(img_batch):
      img_batch[id] = self.augmenter.random_transform(img)
    img_batch = self.augmenter.standardize(img_batch)
    return img_batch

  def __get_data(self, batch_df):
    
    # batch_df is of form [A, B, C, y, transform_n] x n
    batch_A = self.__get_image_batch(batch_df['A'])
    batch_B = self.__get_image_batch(batch_df['B'])
    batch_C = self.__get_image_batch(batch_df['C'])
    #show_images(batch_A)
    batch_A = self.__get_transform(batch_A)
    #show_images(batch_A)
    batch_B = self.__get_transform(batch_B)
    batch_C = self.__get_transform(batch_C)
    X = [batch_A, batch_B, batch_C]
    y = batch_df['y'].to_numpy()
    return X, y

  def on_epoch_end(self):
    if self.shuffle:
      self.df = self.df.sample(frac=1, random_state=self.seed).reset_index(drop=True)
  
  def __getitem__(self, index):
    batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]
    X, y = self.__get_data(batches)
    return X, y
  
  def __len__(self):
    return self.n // self.batch_size

testDG = task4DataGenerator(train_split, batch_size=2, augmenter=trainAug)
X, y = testDG[0]

trainGN = task4DataGenerator(train_split, do_multiply=True, augmenter=trainAug, batch_size=BATCH_SIZE)
valGN = task4DataGenerator(val_split, augmenter=valAug, batch_size=BATCH_SIZE)
testGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE)

"""Let's try to follow [this](https://www.pyimagesearch.com/2020/04/27/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning/) example for a bit in regards to fine tuning the ResNet network"""

# TODO https://keras.io/api/applications/resnet/ use ResNet50v2 and then one last time ResNet152v2
def getBaseModelRN50(input_shape=(224, 224, 3)):
  # ImageNet trained ResNet50
  baseModel = ResNet50(
      include_top=False,
      weights="imagenet",
      input_tensor=None,
      input_shape=input_shape,
      pooling=None,
      classifier_activation="softmax",
  )
  for layer in baseModel.layers:
    layer.trainable = False
  return baseModel

def getSingleImgModel50():
  # The following builds a new head for the baseModel to get the flatten
  baseModel = getBaseModelRN50()
  headModel = baseModel.output
  headModel = AveragePooling2D(pool_size=(7, 7))(headModel)
  #headModel = AveragePooling2D(pool_size=(3, 3))(headModel) # upper or this
  headModel = Flatten(name="flatten")(headModel)
  # place the head model on top of the base model (this will become
  # the model for each picture we use)
  return Model(inputs=baseModel.input, outputs=headModel)

METRICS = [
      keras.metrics.TruePositives(name='tp'),
      keras.metrics.FalsePositives(name='fp'),
      keras.metrics.TrueNegatives(name='tn'),
      keras.metrics.FalseNegatives(name='fn'), 
      keras.metrics.BinaryAccuracy(name='accuracy'),
      keras.metrics.Precision(name='precision'),
      keras.metrics.Recall(name='recall'),
      keras.metrics.AUC(name='auc'),
      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve
]

def make_model(metrics=METRICS, output_bias=None, last_layer=1):
  modelA = getSingleImgModel50()
  modelB = getSingleImgModel50()
  modelC = getSingleImgModel50()
  #Fix layer naming as otherwise we have colissions
  for layer in modelA.layers :
    layer._name = layer.name + str('_A')
  for layer in modelB.layers :
    layer._name = layer.name + str('_B')
  for layer in modelC.layers :
    layer._name = layer.name + str('_C')

  # we use 3 times ImageNet to get the features from the 3 images combined
  concat = Concatenate()([modelA.outputs[0], modelB.outputs[0], modelC.outputs[0]])
  headModel = Dense(256, activation="relu")(concat)
  headModel = Dropout(0.5)(headModel)
  #headModel = Dense(128, activation="relu")(headModel)
  #headModel = Dropout(0.5)(headModel)
  headModel = Dense(1, activation='sigmoid')(headModel)

  model = Model(inputs=[modelA.input, modelB.input, modelC.input], outputs=[headModel])

  # actually compile it now
  model.compile(
      optimizer=keras.optimizers.Adam(lr=1e-3),
      loss=keras.losses.binary_crossentropy,
      metrics=metrics)

  return model

early_stopping = keras.callbacks.EarlyStopping(
    monitor='val_roc', 
    verbose=1,
    patience=10,
    mode='max',
    restore_best_weights=True)

# TODO might wanna add a ModelCheckpoint as well?

print("Making model")
model = make_model()
print("Starting to fit")
fitted = model.fit(
    trainGN,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    callbacks=[early_stopping],
    validation_data=valGN,
    verbose=1)
print("Done fitting")

"""Save model"""

# serialize model to JSON
model_json = fitted.to_json()
with open("fitted.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
fitted.save_weights("model.h5")
print("Saved model to disk")

submission_predicted.to_csv("testOut.csv", index=False, header=False)
