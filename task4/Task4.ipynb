{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwCJDlDblbfn"
   },
   "source": [
    "### Trying to solve Task 4 now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oeL297NoB-yf"
   },
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.4)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.8.0-cp36-cp36m-manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 121.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 112.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 107.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 121.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=25ac3524309e5f6599e8b8cd0f513cdbd898f295ade4a54a195a806ac9a2555b\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: scipy, threadpoolctl, joblib, scikit-learn, sklearn, psutil, pytz, pandas\n",
      "Successfully installed joblib-1.0.1 pandas-1.1.5 psutil-5.8.0 pytz-2021.1 scikit-learn-0.24.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn numpy matplotlib psutil pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard_plugin_profile\n",
      "  Downloading tensorboard_plugin_profile-2.4.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (56.2.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (3.17.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (1.15.0)\n",
      "Collecting gviz-api>=1.9.0\n",
      "  Downloading gviz_api-1.9.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from werkzeug>=0.11.15->tensorboard_plugin_profile) (0.8)\n",
      "Installing collected packages: gviz-api, tensorboard-plugin-profile\n",
      "Successfully installed gviz-api-1.9.0 tensorboard-plugin-profile-2.4.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorboard_plugin_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c6f66d24083b2434\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c6f66d24083b2434\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/ --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "oehqk2wZPnlF",
    "outputId": "42abd04d-aed9-4c82-9bfa-55ead3b93fd7"
   },
   "outputs": [],
   "source": [
    "# run for a remote notebook: docker run -it --gpus all -v /root/iml2021/task4:/tf/task4 -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter\n",
    "# need stuff cd /task4 && python -m pip install sklearn numpy matplotlib psutil pandas && python3 task4.py\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "#from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from lru_cache_memory_aware import lru_cache\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW_pdKJmXr1R"
   },
   "source": [
    "Following is the example by keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cSG9RinbUd5M"
   },
   "outputs": [],
   "source": [
    "# TODO https://keras.io/api/applications/resnet/ use ResNet50v2 and then one last time ResNet152v2\n",
    "def example():\n",
    "  model = ResNet50(\n",
    "      include_top=True,\n",
    "      weights=\"imagenet\",\n",
    "      input_tensor=None,\n",
    "      input_shape=None,\n",
    "      pooling=None,\n",
    "      classes=1000,\n",
    "      classifier_activation=\"softmax\",\n",
    "  )\n",
    "  img_path = 'food/00000.jpg'\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "\n",
    "  preds = model.predict(x)\n",
    "  # decode the results into a list of tuples (class, description, probability)\n",
    "  # (one such list for each sample in the batch)\n",
    "  print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MwoeX2dz9hu-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip -o food.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "hk0UmvvRcLFY",
    "outputId": "201a00bf-ece3-4b94-e7bb-44d0544b8a67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2762</td>\n",
       "      <td>3127</td>\n",
       "      <td>1659</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1531</td>\n",
       "      <td>62</td>\n",
       "      <td>3849</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1514</td>\n",
       "      <td>1885</td>\n",
       "      <td>373</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601</td>\n",
       "      <td>4295</td>\n",
       "      <td>845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1306</td>\n",
       "      <td>3411</td>\n",
       "      <td>4212</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238055</th>\n",
       "      <td>3177</td>\n",
       "      <td>1791</td>\n",
       "      <td>1130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238056</th>\n",
       "      <td>714</td>\n",
       "      <td>1913</td>\n",
       "      <td>3094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238057</th>\n",
       "      <td>2801</td>\n",
       "      <td>62</td>\n",
       "      <td>1828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238058</th>\n",
       "      <td>709</td>\n",
       "      <td>1363</td>\n",
       "      <td>1010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238059</th>\n",
       "      <td>4385</td>\n",
       "      <td>665</td>\n",
       "      <td>966</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y\n",
       "0       2762  3127  1659  0.0\n",
       "1       1531    62  3849  1.0\n",
       "2       1514  1885   373  1.0\n",
       "3       2601  4295   845  1.0\n",
       "4       1306  3411  4212  1.0\n",
       "...      ...   ...   ...  ...\n",
       "238055  3177  1791  1130  1.0\n",
       "238056   714  1913  3094  0.0\n",
       "238057  2801    62  1828  1.0\n",
       "238058   709  1363  1010  1.0\n",
       "238059  4385   665   966  1.0\n",
       "\n",
       "[238060 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPD = pd.read_csv(\"train_triplets.txt\", header=None, delimiter=' ')\n",
    "testPD = pd.read_csv(\"test_triplets.txt\", header=None, delimiter=' ')\n",
    "# Add the y lable, where 1 means exactly what the exercise defines,\n",
    "# i.e. 0 is closer in taste to 1 than 2\n",
    "trainPDreverse = trainPD.copy()\n",
    "trainPDreverse[1] = trainPD[2].copy()\n",
    "trainPDreverse[2] = trainPD[1].copy()\n",
    "trainPD['y'] = pd.DataFrame(np.ones((trainPD.shape[0],1)), columns=[\"y\"])\n",
    "trainPDreverse['y'] = pd.DataFrame(np.zeros((trainPDreverse.shape[0],1)), columns=[\"y\"])\n",
    "trainPD = trainPD.append(trainPDreverse).reset_index(drop=True)\n",
    "# TODO move B to A -> same lable, but a should make for more diverse input with same idea behind it\n",
    "trainPDreverseF = trainPD.copy()\n",
    "trainPDreverseF[0] = trainPD[1].copy()\n",
    "trainPDreverseF[1] = trainPD[0].copy()\n",
    "trainPD = trainPD.append(trainPDreverseF).reset_index(drop=True)\n",
    "# Give labels and reshuffle\n",
    "trainPD.columns = ['A', 'B', 'C', 'y']\n",
    "trainPD = trainPD.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "trainPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJddS7B4ui7F"
   },
   "source": [
    "Prepare the data splits  \n",
    "TODO: create the generator with turning and then combine the correct 3 always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "wFOw0IBJt6aa",
    "outputId": "acd9c173-80d6-4bcd-d767-b0e0ab4d105f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214254, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60764</th>\n",
       "      <td>2640</td>\n",
       "      <td>3419</td>\n",
       "      <td>4488</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103755</th>\n",
       "      <td>4877</td>\n",
       "      <td>851</td>\n",
       "      <td>2256</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y\n",
       "60764   2640  3419  4488  0.0\n",
       "103755  4877   851  2256  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split picture combinations\n",
    "def createTrainSplit(df):\n",
    "  global train_split, test_split, val_split\n",
    "  train_split, test_split = train_test_split(df, test_size=0.1, random_state=random_state)\n",
    "  #train_split, val_split = train_test_split(train_split, test_size=0.2, random_state=random_state)\n",
    "\n",
    "createTrainSplit(trainPD)\n",
    "print(train_split.shape)\n",
    "train_split.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FDsZxP7E0rH"
   },
   "source": [
    "Let's do the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "joY6BRUTEz3m"
   },
   "outputs": [],
   "source": [
    "# TODO maybe think if actually using resnet preprocess_input is ok\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCBINL80LUgK"
   },
   "source": [
    "SHIT we have to write our own generator because of the different input... [example](https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7eq6Zs-vCZBg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "      <th>transform_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2640</td>\n",
       "      <td>3419</td>\n",
       "      <td>4488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2640</td>\n",
       "      <td>3419</td>\n",
       "      <td>4488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4877</td>\n",
       "      <td>851</td>\n",
       "      <td>2256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4877</td>\n",
       "      <td>851</td>\n",
       "      <td>2256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4068</td>\n",
       "      <td>367</td>\n",
       "      <td>1567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428503</th>\n",
       "      <td>969</td>\n",
       "      <td>720</td>\n",
       "      <td>191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428504</th>\n",
       "      <td>3243</td>\n",
       "      <td>4276</td>\n",
       "      <td>3461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428505</th>\n",
       "      <td>3243</td>\n",
       "      <td>4276</td>\n",
       "      <td>3461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428506</th>\n",
       "      <td>2881</td>\n",
       "      <td>4180</td>\n",
       "      <td>3300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428507</th>\n",
       "      <td>2881</td>\n",
       "      <td>4180</td>\n",
       "      <td>3300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428508 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y  transform_n\n",
       "0       2640  3419  4488  0.0            0\n",
       "1       2640  3419  4488  0.0            1\n",
       "2       4877   851  2256  0.0            0\n",
       "3       4877   851  2256  0.0            1\n",
       "4       4068   367  1567  1.0            0\n",
       "...      ...   ...   ...  ...          ...\n",
       "428503   969   720   191  0.0            1\n",
       "428504  3243  4276  3461  1.0            0\n",
       "428505  3243  4276  3461  1.0            1\n",
       "428506  2881  4180  3300  1.0            0\n",
       "428507  2881  4180  3300  1.0            1\n",
       "\n",
       "[428508 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply_df(amount, df:pd.DataFrame):\n",
    "  ret = df.copy()\n",
    "  ret = ret.apply(lambda row: row.loc[row.index.repeat(amount)], axis=0).reset_index(drop=True)\n",
    "  # now add the transform_n just to see in index afterwards\n",
    "  ns = np.concatenate(list(itertools.repeat(np.arange(0,amount), df.shape[0])))\n",
    "  ret[\"transform_n\"] = pd.DataFrame(ns,columns=[\"transform_n\"])\n",
    "  return ret\n",
    "\n",
    "multiply_df(2, train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "x77kcv4UFz1e"
   },
   "outputs": [],
   "source": [
    "def show_images(images: [np.ndarray]) -> None:\n",
    "    n: int = len(images)\n",
    "    f = plt.figure()\n",
    "    for i in range(n):\n",
    "        # Debug, plot figure\n",
    "        f.add_subplot(1, n, i + 1)\n",
    "        plt.imshow(image.array_to_img(images[i]))\n",
    "\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_index):\n",
    "    path = f\"food/{str(image_index).zfill(5)}.jpg\"\n",
    "    h, w, = (224, 224)\n",
    "    img = image.load_img(path, target_size=(h, w))\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "imageDict = {}\n",
    "for i in range(0, 10000):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    imageDict[i] = load_image(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cpus = multiprocessing.cpu_count()\n",
    "except NotImplementedError:\n",
    "    cpus = 2   # arbitrary default\n",
    "pool = multiprocessing.Pool(processes=cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y1VoR1bkLfGU"
   },
   "outputs": [],
   "source": [
    "class task4DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "  def __init__(self, df,\n",
    "                batch_size=1024,\n",
    "                input_size=(224, 224, 3),\n",
    "                augmenter:ImageDataGenerator=None,\n",
    "                shuffle=False,\n",
    "                seed=42,\n",
    "                amount_augmented=1,\n",
    "                do_multiply=False,\n",
    "                do_augment=False,\n",
    "                ret_labels=True\n",
    "               ):\n",
    "        \n",
    "    self.df = multiply_df(amount_augmented, df) if do_multiply else df\n",
    "    self.batch_size = batch_size\n",
    "    self.input_size = input_size\n",
    "    self.shuffle = shuffle\n",
    "    self.seed = seed\n",
    "    self.do_augment = do_augment\n",
    "    self.augmenter:ImageDataGenerator = augmenter\n",
    "    self.amount_augmented = amount_augmented\n",
    "    self.ret_labels = ret_labels\n",
    "\n",
    "    self.n = len(self.df)\n",
    "\n",
    "  # GB = 1024**3\n",
    "  #@lru_cache(use_memory_up_to=(leave_free_GB * 1024**3))\n",
    "  #def __load_image(self, image_index):\n",
    "  #  path = f\"food/{str(image_index).zfill(5)}.jpg\"\n",
    "  #  h, w, chann = self.input_size\n",
    "  #  img = image.load_img(path, target_size=(h, w))\n",
    "  #  img = image.img_to_array(img)\n",
    "  #  return img\n",
    "\n",
    "  def __get_image_batch(self, img_indices):\n",
    "    batch = [imageDict[x] for _, x in img_indices.iteritems()]\n",
    "    batch = np.stack( batch, axis=0 )\n",
    "    return batch\n",
    "\n",
    "  def __get_transform(self, img_batch):\n",
    "    # returns the transformed img_batch if augmenter defined\n",
    "    # TODO check if the random_transform returns a copy or else \n",
    "    # use https://stackoverflow.com/questions/54909357/how-to-get-functools-lru-cache-to-return-new-instances\n",
    "    # to return copy of load_img\n",
    "    # TODO self seed probably does not do it here! , seed=self.seed\n",
    "    #img_batch = [self.augmenter.random_transform(img, seed=self.seed) for img in img_batch], axis=0 )\n",
    "    if self.do_augment:\n",
    "    #    img_batch = pool.map(self.augmenter.random_transform, img_batch)\n",
    "    #    img_batch = np.stack(img_batch, axis=0)\n",
    "        for i, img in enumerate(img_batch):\n",
    "            img_batch[i] = self.augmenter.random_transform(img, seed=self.seed)\n",
    "    img_batch = self.augmenter.standardize(img_batch)\n",
    "    return img_batch\n",
    "\n",
    "  def __get_data(self, batch_df):\n",
    "    \n",
    "    # batch_df is of form [A, B, C, y, transform_n] x n\n",
    "    batch_A = self.__get_image_batch(batch_df['A'])\n",
    "    batch_B = self.__get_image_batch(batch_df['B'])\n",
    "    batch_C = self.__get_image_batch(batch_df['C'])\n",
    "    #show_images(batch_A)\n",
    "    batch_A = self.__get_transform(batch_A)\n",
    "    #show_images(batch_A)\n",
    "    batch_B = self.__get_transform(batch_B)\n",
    "    batch_C = self.__get_transform(batch_C)\n",
    "    X = [batch_A, batch_B, batch_C]\n",
    "    y = batch_df['y'].to_numpy() if self.ret_labels else []\n",
    "    return X, y\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    if self.shuffle:\n",
    "      self.df = self.df.sample(frac=1, random_state=self.seed).reset_index(drop=True)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "    X, y = self.__get_data(batches)\n",
    "    return X, y\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.n // self.batch_size\n",
    "\n",
    "testDG = task4DataGenerator(train_split, batch_size=2, augmenter=trainAug)\n",
    "X, y = testDG[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HwIijdHWBuIi"
   },
   "outputs": [],
   "source": [
    "trainGN = task4DataGenerator(train_split, do_augment=True, do_multiply=True, \n",
    "                             augmenter=trainAug, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "valGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE)\n",
    "# let's use the public score as test actually\n",
    "#testGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ6SEW3LyRdg"
   },
   "source": [
    "Let's try to follow [this](https://www.pyimagesearch.com/2020/04/27/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning/) example for a bit in regards to fine tuning the ResNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gT8hPGpttumv"
   },
   "outputs": [],
   "source": [
    "# TODO https://keras.io/api/applications/resnet/ use ResNet50v2 and then one last time ResNet152v2\n",
    "def getBaseModelRN50(input_shape=(224, 224, 3)):\n",
    "  # ImageNet trained ResNet50\n",
    "  baseModel = ResNet50(\n",
    "      include_top=False,\n",
    "      weights=\"imagenet\",\n",
    "      input_tensor=None,\n",
    "      input_shape=input_shape,\n",
    "      pooling=None,\n",
    "      classifier_activation=\"softmax\",\n",
    "  )\n",
    "  for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "  return baseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_No7pa4cgpVz"
   },
   "outputs": [],
   "source": [
    "def getMobileNet(input_shape=(224, 224, 3)):\n",
    "  baseModel = MobileNet(\n",
    "    input_shape=input_shape,\n",
    "    alpha=1.0,\n",
    "    depth_multiplier=1,\n",
    "    dropout=0.001,\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classifier_activation=\"softmax\")\n",
    "  for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "  return baseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wsgZpy_e8CIW"
   },
   "outputs": [],
   "source": [
    "def getSingleImgModel50(baseModel, inp):\n",
    "  # The following builds a new head for the baseModel to get the flatten\n",
    "  headModel = baseModel(inp)\n",
    "  #headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "  headModel = AveragePooling2D(pool_size=(4, 4))(headModel) # upper or this\n",
    "  headModel = Flatten(name=\"flatten\")(headModel)\n",
    "  #headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "  # place the head model on top of the base model (this will become\n",
    "  # the model for each picture we use)\n",
    "  return Model(inputs=inp, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YQWrpaXe533B"
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  #baseModel = None\n",
    "  baseModel = getBaseModelRN50()\n",
    "  input_A = keras.Input(shape=(224, 224, 3), name='input_A')\n",
    "  input_B = keras.Input(shape=(224, 224, 3), name='input_B')\n",
    "  input_C = keras.Input(shape=(224, 224, 3), name='input_C')\n",
    "  modelA = getSingleImgModel50(baseModel, input_A)\n",
    "  modelB = getSingleImgModel50(baseModel, input_B)\n",
    "  modelC = getSingleImgModel50(baseModel, input_C)\n",
    "  #Fix layer naming as otherwise we have colissions\n",
    "  for layer in modelA.layers :\n",
    "    if \"input\" not in layer._name:\n",
    "        layer._name = layer.name + str('_A')\n",
    "  for layer in modelB.layers :\n",
    "    if \"input\" not in layer._name:\n",
    "        layer._name = layer.name + str('_B')\n",
    "  for layer in modelC.layers :\n",
    "    if \"input\" not in layer._name:\n",
    "        layer._name = layer.name + str('_C')\n",
    "\n",
    "  # we use 3 times ImageNet to get the features from the 3 images combined\n",
    "  concat = Concatenate()([modelA.outputs[0], modelB.outputs[0], modelC.outputs[0]])\n",
    "  headModel = Dropout(0.5)(concat)\n",
    "  headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "  headModel = Dropout(0.5)(headModel)\n",
    "  headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "  headModel = Dropout(0.5)(headModel)\n",
    "  #headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "  #headModel = Dropout(0.5)(headModel)\n",
    "  #headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "  #headModel = Dropout(0.25)(headModel)\n",
    "  headModel = Dense(1, activation='sigmoid')(headModel)\n",
    "  # try https://github.com/noelcodella/tripletloss-keras-tensorflow/blob/master/tripletloss.py\n",
    "  model = Model(inputs=[input_A, input_B, input_C], outputs=[headModel])\n",
    "\n",
    "  # actually compile it now\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.binary_crossentropy,\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "TMyNuFaxg54M",
    "outputId": "9f5cc07f-7cb9-495f-8a29-adae0e7a2da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 2s 0us/step\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_A (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_B (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_C (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50_A_B_C (Functional)     (None, 7, 7, 2048)   23587712    input_A[0][0]                    \n",
      "                                                                 input_B[0][0]                    \n",
      "                                                                 input_C[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_A (AveragePoo (None, 1, 1, 2048)   0           resnet50_A_B_C[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1_B (AverageP (None, 1, 1, 2048)   0           resnet50_A_B_C[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2_C (AverageP (None, 1, 1, 2048)   0           resnet50_A_B_C[2][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_A (Flatten)             (None, 2048)         0           average_pooling2d_A[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_B (Flatten)             (None, 2048)         0           average_pooling2d_1_B[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_C (Flatten)             (None, 2048)         0           average_pooling2d_2_C[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6144)         0           flatten_A[0][0]                  \n",
      "                                                                 flatten_B[0][0]                  \n",
      "                                                                 flatten_C[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 6144)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          3146240     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            513         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,997,121\n",
      "Trainable params: 3,409,409\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "make_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hPuVKCpbAH5S"
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "#tboard_callback = keras.callbacks.TensorBoard(log_dir = logs, update_freq=50)\n",
    "tboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir = logs,\n",
    "    histogram_freq = 1,\n",
    "    profile_batch=(10,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoint/'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "1UaZienz__oe",
    "outputId": "61249214-22d4-42c1-b0a6-34c3e20a53cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model\n",
      "Starting to fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 256/1673 [===>..........................] - ETA: 21:50 - loss: 0.6643 - tp: 5319.0000 - fp: 2700.0000 - tn: 13491.0000 - fn: 11258.0000 - accuracy: 0.5740 - precision: 0.6633 - recall: 0.3209 - auc: 0.6158 - prc: 0.6353"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-12:\n",
      "Process Keras_worker_ForkPoolWorker-9:\n",
      "Process Keras_worker_ForkPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-13:\n",
      "Process Keras_worker_ForkPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Keras_worker_ForkPoolWorker-16:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 547, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 77, in __getitem__\n",
      "    X, y = self.__get_data(batches)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 547, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "Process Keras_worker_ForkPoolWorker-15:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 63, in __get_data\n",
      "    batch_A = self.__get_transform(batch_A)\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 77, in __getitem__\n",
      "    X, y = self.__get_data(batches)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 66, in __get_data\n",
      "    batch_C = self.__get_transform(batch_C)\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 52, in __get_transform\n",
      "    img_batch[i] = self.augmenter.random_transform(img, seed=self.seed)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 547, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 547, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 77, in __getitem__\n",
      "    X, y = self.__get_data(batches)\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 52, in __get_transform\n",
      "    img_batch[i] = self.augmenter.random_transform(img, seed=self.seed)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\", line 903, in random_transform\n",
      "    return self.apply_transform(x, params)\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 77, in __getitem__\n",
      "    X, y = self.__get_data(batches)\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 65, in __get_data\n",
      "    batch_B = self.__get_transform(batch_B)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\", line 874, in apply_transform\n",
      "    order=self.interpolation_order)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in apply_affine_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\", line 903, in random_transform\n",
      "    return self.apply_transform(x, params)\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 66, in __get_data\n",
      "    batch_C = self.__get_transform(batch_C)\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 52, in __get_transform\n",
      "    img_batch[i] = self.augmenter.random_transform(img, seed=self.seed)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\", line 874, in apply_transform\n",
      "    order=self.interpolation_order)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\", line 903, in random_transform\n",
      "    return self.apply_transform(x, params)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\", line 547, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 52, in __get_transform\n",
      "    img_batch[i] = self.augmenter.random_transform(img, seed=self.seed)\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 77, in __getitem__\n",
      "    X, y = self.__get_data(batches)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 528, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in apply_affine_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\", line 874, in apply_transform\n",
      "    order=self.interpolation_order)\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 59, in __get_data\n",
      "    batch_A = self.__get_image_batch(batch_df['A'])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in apply_affine_transform\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 528, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-17-7a2e34464e89>\", line 38, in __get_image_batch\n",
      "    batch = np.stack( batch, axis=0 )\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py\", line 333, in <listcomp>\n",
      "    cval=cval) for x_channel in x]\n",
      "  File \"<__array_function__ internals>\", line 6, in stack\n",
      "Process Keras_worker_ForkPoolWorker-11:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/ndimage/interpolation.py\", line 528, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/shape_base.py\", line 434, in stack\n",
      "    return _nx.concatenate(expanded_arrays, axis=axis, out=out)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 341, in put\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-47d530560c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     verbose=1)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done fitting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Making model\")\n",
    "model = make_model()\n",
    "model.load_weights(checkpoint_filepath)\n",
    "print(\"Starting to fit\")\n",
    "fitted = model.fit(\n",
    "    trainGN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, tboard_callback, model_checkpoint_callback],\n",
    "    validation_data=valGN,\n",
    "    use_multiprocessing = True,\n",
    "    workers=8,\n",
    "    verbose=1)\n",
    "print(\"Done fitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that checkpointing acutally works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 170s 895ms/step - loss: 0.7830 - tp: 7420.0000 - fp: 4793.0000 - tn: 23329.0000 - fn: 21034.0000 - accuracy: 0.5435 - precision: 0.6075 - recall: 0.2608 - auc: 0.5585 - prc: 0.5838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7830327153205872,\n",
       " 7420.0,\n",
       " 4793.0,\n",
       " 23329.0,\n",
       " 21034.0,\n",
       " 0.5434989929199219,\n",
       " 0.6075493097305298,\n",
       " 0.260771781206131,\n",
       " 0.5584668517112732,\n",
       " 0.5838417410850525]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.evaluate(valGN, verbose=1, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 164s 884ms/step - loss: 0.6433 - tp: 5723.0000 - fp: 2656.0000 - tn: 9209.0000 - fn: 6092.0000 - accuracy: 0.6306 - precision: 0.6830 - recall: 0.4844 - auc: 0.6829 - prc: 0.6829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.643280565738678,\n",
       " 5723.0,\n",
       " 2656.0,\n",
       " 9209.0,\n",
       " 6092.0,\n",
       " 0.6305743455886841,\n",
       " 0.6830170750617981,\n",
       " 0.4843842685222626,\n",
       " 0.68292635679245,\n",
       " 0.6829150319099426]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath)\n",
    "model.evaluate(valGN, verbose=1, workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually create the output for the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9896</td>\n",
       "      <td>9640</td>\n",
       "      <td>9177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6592</td>\n",
       "      <td>9283</td>\n",
       "      <td>7104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8655</td>\n",
       "      <td>6174</td>\n",
       "      <td>6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9223</td>\n",
       "      <td>8187</td>\n",
       "      <td>8678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7317</td>\n",
       "      <td>5392</td>\n",
       "      <td>9470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59539</th>\n",
       "      <td>6113</td>\n",
       "      <td>8042</td>\n",
       "      <td>6277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59540</th>\n",
       "      <td>8851</td>\n",
       "      <td>6075</td>\n",
       "      <td>8549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59541</th>\n",
       "      <td>6299</td>\n",
       "      <td>7843</td>\n",
       "      <td>7940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59542</th>\n",
       "      <td>7652</td>\n",
       "      <td>5620</td>\n",
       "      <td>5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59543</th>\n",
       "      <td>8475</td>\n",
       "      <td>6082</td>\n",
       "      <td>9044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59544 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          A     B     C\n",
       "0      9896  9640  9177\n",
       "1      6592  9283  7104\n",
       "2      8655  6174  6400\n",
       "3      9223  8187  8678\n",
       "4      7317  5392  9470\n",
       "...     ...   ...   ...\n",
       "59539  6113  8042  6277\n",
       "59540  8851  6075  8549\n",
       "59541  6299  7843  7940\n",
       "59542  7652  5620  5416\n",
       "59543  8475  6082  9044\n",
       "\n",
       "[59544 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPD.columns = ['A', 'B', 'C']\n",
    "submissionGN = task4DataGenerator(testPD, augmenter=valAug, batch_size=8, ret_labels=False)\n",
    "testPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff9dc6636a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = make_model()\n",
    "test.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7443/7443 [==============================] - 417s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "res = test.predict(submissionGN, verbose=1, use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.498339    18517\n",
       "0.412985        6\n",
       "0.275147        5\n",
       "0.208707        4\n",
       "0.696023        4\n",
       "            ...  \n",
       "0.556275        1\n",
       "0.556268        1\n",
       "0.556251        1\n",
       "0.556246        1\n",
       "0.097741        1\n",
       "Length: 40776, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(res)\n",
    "res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.498339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.628882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59539</th>\n",
       "      <td>0.227854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59540</th>\n",
       "      <td>0.364465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59541</th>\n",
       "      <td>0.498339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59542</th>\n",
       "      <td>0.498339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59543</th>\n",
       "      <td>0.346700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59544 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      0.498339\n",
       "1      0.279280\n",
       "2      0.498339\n",
       "3      0.428493\n",
       "4      0.628882\n",
       "...         ...\n",
       "59539  0.227854\n",
       "59540  0.364465\n",
       "59541  0.498339\n",
       "59542  0.498339\n",
       "59543  0.346700\n",
       "\n",
       "[59544 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks strongly like my model has no idea what to do with half of the inputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change shape and threshold to 0 1 for submission\n",
      "(59544,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59539</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59540</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59541</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59542</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59543</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59544 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "...   ..\n",
       "59539  0\n",
       "59540  0\n",
       "59541  0\n",
       "59542  0\n",
       "59543  0\n",
       "\n",
       "[59544 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Change shape and threshold to 0 1 for submission')\n",
    "seq_predictions=np.transpose(res.to_numpy())[0]  # transformation to get (n,)\n",
    "print(seq_predictions.shape)  # now the shape is (n,)\n",
    "# Applying transformation to get binary values predictions with 0.5 as thresold\n",
    "seq_predictions = list(map(lambda x: 0 if x<0.5 else 1, seq_predictions))\n",
    "seq_predictions = pd.DataFrame(seq_predictions)\n",
    "seq_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "vvyuMd0XbWu6"
   },
   "outputs": [],
   "source": [
    "seq_predictions.to_csv(\"outThreeModel.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQLKF5XjVpfGVnyYGIq1JW",
   "name": "Task4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
