{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwCJDlDblbfn"
   },
   "source": [
    "### Trying to solve Task 4 now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oeL297NoB-yf"
   },
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "BATCH_SIZE_IM = 16\n",
    "EMB_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.4)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.8.0-cp36-cp36m-manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 15.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 127.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 126.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 91.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 121.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=3a35a954683391e18d366875c2a555e428ad5cdf5656ac913d3d2c31a5854f7e\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: scipy, joblib, threadpoolctl, scikit-learn, sklearn, psutil, pytz, pandas\n",
      "Successfully installed joblib-1.0.1 pandas-1.1.5 psutil-5.8.0 pytz-2021.1 scikit-learn-0.24.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn numpy matplotlib psutil pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard_plugin_profile\n",
      "  Downloading tensorboard_plugin_profile-2.4.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (2.0.0)\n",
      "Collecting gviz-api>=1.9.0\n",
      "  Downloading gviz_api-1.9.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (3.17.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (56.2.0)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from werkzeug>=0.11.15->tensorboard_plugin_profile) (0.8)\n",
      "Installing collected packages: gviz-api, tensorboard-plugin-profile\n",
      "Successfully installed gviz-api-1.9.0 tensorboard-plugin-profile-2.4.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorboard_plugin_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6df9a235dc124793\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6df9a235dc124793\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/ --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "oehqk2wZPnlF",
    "outputId": "42abd04d-aed9-4c82-9bfa-55ead3b93fd7"
   },
   "outputs": [],
   "source": [
    "# run for a remote notebook: docker run -it --gpus all -v /root/iml2021/task4:/tf/task4 -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter\n",
    "# need stuff cd /task4 && python -m pip install sklearn numpy matplotlib psutil pandas && python3 task4.py\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "#from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Concatenate, Lambda, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from lru_cache_memory_aware import lru_cache\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW_pdKJmXr1R"
   },
   "source": [
    "Following is the example by keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cSG9RinbUd5M"
   },
   "outputs": [],
   "source": [
    "# TODO https://keras.io/api/applications/resnet/ use ResNet50v2 and then one last time ResNet152v2\n",
    "def example():\n",
    "  model = ResNet50(\n",
    "      include_top=True,\n",
    "      weights=\"imagenet\",\n",
    "      input_tensor=None,\n",
    "      input_shape=None,\n",
    "      pooling=None,\n",
    "      classes=1000,\n",
    "      classifier_activation=\"softmax\",\n",
    "  )\n",
    "  img_path = 'food/00000.jpg'\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "\n",
    "  preds = model.predict(x)\n",
    "  # decode the results into a list of tuples (class, description, probability)\n",
    "  # (one such list for each sample in the batch)\n",
    "  print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MwoeX2dz9hu-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip -o food.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPD = pd.read_csv(\"train_triplets.txt\", header=None, delimiter=' ')\n",
    "testPD = pd.read_csv(\"test_triplets.txt\", header=None, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1623</td>\n",
       "      <td>1263</td>\n",
       "      <td>4221</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2841</td>\n",
       "      <td>4262</td>\n",
       "      <td>3258</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3453</td>\n",
       "      <td>1963</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1205</td>\n",
       "      <td>3519</td>\n",
       "      <td>4785</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3427</td>\n",
       "      <td>2101</td>\n",
       "      <td>2799</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119025</th>\n",
       "      <td>1431</td>\n",
       "      <td>1397</td>\n",
       "      <td>3914</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119026</th>\n",
       "      <td>1044</td>\n",
       "      <td>1728</td>\n",
       "      <td>3374</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119027</th>\n",
       "      <td>2832</td>\n",
       "      <td>1682</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119028</th>\n",
       "      <td>2864</td>\n",
       "      <td>3614</td>\n",
       "      <td>2252</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119029</th>\n",
       "      <td>1201</td>\n",
       "      <td>4875</td>\n",
       "      <td>3612</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119030 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y\n",
       "0       1623  1263  4221  1.0\n",
       "1       2841  4262  3258  1.0\n",
       "2          2  3453  1963  1.0\n",
       "3       1205  3519  4785  1.0\n",
       "4       3427  2101  2799  1.0\n",
       "...      ...   ...   ...  ...\n",
       "119025  1431  1397  3914  1.0\n",
       "119026  1044  1728  3374  1.0\n",
       "119027  2832  1682    26  1.0\n",
       "119028  2864  3614  2252  1.0\n",
       "119029  1201  4875  3612  1.0\n",
       "\n",
       "[119030 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the y lable, where 1 means exactly what the exercise defines,\n",
    "# i.e. 0 is closer in taste to 1 than 2\n",
    "trainPD['y'] = pd.DataFrame(np.ones((trainPD.shape[0],1)), columns=[\"y\"])\n",
    "trainPD.columns = ['A', 'B', 'C', 'y']\n",
    "trainPD = trainPD.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "trainPDreverseF = trainPD.copy()\n",
    "trainPDreverseF[\"A\"] = trainPD[\"B\"].copy()\n",
    "trainPDreverseF[\"B\"] = trainPD[\"A\"].copy()\n",
    "trainPD = trainPD.append(trainPDreverseF).reset_index(drop=True)\n",
    "trainPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJddS7B4ui7F"
   },
   "source": [
    "Prepare the data splits  \n",
    "TODO: create the generator with turning and then combine the correct 3 always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "wFOw0IBJt6aa",
    "outputId": "acd9c173-80d6-4bcd-d767-b0e0ab4d105f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113078, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88856</th>\n",
       "      <td>4621</td>\n",
       "      <td>1127</td>\n",
       "      <td>2103</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79169</th>\n",
       "      <td>824</td>\n",
       "      <td>2817</td>\n",
       "      <td>4313</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A     B     C    y\n",
       "88856  4621  1127  2103  1.0\n",
       "79169   824  2817  4313  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split picture combinations\n",
    "def createTrainSplit(df):\n",
    "  global train_split, test_split, val_split\n",
    "  train_split, test_split = train_test_split(df, test_size=0.05, random_state=random_state)\n",
    "  #train_split, val_split = train_test_split(train_split, test_size=0.2, random_state=random_state)\n",
    "\n",
    "createTrainSplit(trainPD)\n",
    "print(train_split.shape)\n",
    "train_split.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FDsZxP7E0rH"
   },
   "source": [
    "Let's do the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "joY6BRUTEz3m"
   },
   "outputs": [],
   "source": [
    "# TODO maybe think if actually using resnet preprocess_input is ok\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCBINL80LUgK"
   },
   "source": [
    "SHIT we have to write our own generator because of the different input... [example](https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "7eq6Zs-vCZBg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "      <th>transform_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4621</td>\n",
       "      <td>1127</td>\n",
       "      <td>2103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4621</td>\n",
       "      <td>1127</td>\n",
       "      <td>2103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>824</td>\n",
       "      <td>2817</td>\n",
       "      <td>4313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>824</td>\n",
       "      <td>2817</td>\n",
       "      <td>4313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3944</td>\n",
       "      <td>2551</td>\n",
       "      <td>2138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226151</th>\n",
       "      <td>2008</td>\n",
       "      <td>3248</td>\n",
       "      <td>3619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226152</th>\n",
       "      <td>2534</td>\n",
       "      <td>3256</td>\n",
       "      <td>4272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226153</th>\n",
       "      <td>2534</td>\n",
       "      <td>3256</td>\n",
       "      <td>4272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226154</th>\n",
       "      <td>2285</td>\n",
       "      <td>1466</td>\n",
       "      <td>306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226155</th>\n",
       "      <td>2285</td>\n",
       "      <td>1466</td>\n",
       "      <td>306</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226156 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y  transform_n\n",
       "0       4621  1127  2103  1.0            0\n",
       "1       4621  1127  2103  1.0            1\n",
       "2        824  2817  4313  1.0            0\n",
       "3        824  2817  4313  1.0            1\n",
       "4       3944  2551  2138  1.0            0\n",
       "...      ...   ...   ...  ...          ...\n",
       "226151  2008  3248  3619  1.0            1\n",
       "226152  2534  3256  4272  1.0            0\n",
       "226153  2534  3256  4272  1.0            1\n",
       "226154  2285  1466   306  1.0            0\n",
       "226155  2285  1466   306  1.0            1\n",
       "\n",
       "[226156 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply_df(amount, df:pd.DataFrame):\n",
    "  ret = df.copy()\n",
    "  ret = ret.apply(lambda row: row.loc[row.index.repeat(amount)], axis=0).reset_index(drop=True)\n",
    "  # now add the transform_n just to see in index afterwards\n",
    "  ns = np.concatenate(list(itertools.repeat(np.arange(0,amount), df.shape[0])))\n",
    "  ret[\"transform_n\"] = pd.DataFrame(ns,columns=[\"transform_n\"])\n",
    "  return ret\n",
    "\n",
    "multiply_df(2, train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "x77kcv4UFz1e"
   },
   "outputs": [],
   "source": [
    "def show_images(images: [np.ndarray]) -> None:\n",
    "    n: int = len(images)\n",
    "    f = plt.figure()\n",
    "    for i in range(n):\n",
    "        # Debug, plot figure\n",
    "        f.add_subplot(1, n, i + 1)\n",
    "        plt.imshow(image.array_to_img(images[i]))\n",
    "\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_index):\n",
    "    path = f\"food/{str(image_index).zfill(5)}.jpg\"\n",
    "    h, w, = (224, 224)\n",
    "    img = image.load_img(path, target_size=(h, w))\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "imageDict = {}\n",
    "for i in range(0, 10000):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    imageDict[i] = load_image(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y1VoR1bkLfGU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class task4DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "  def __init__(self, df,\n",
    "                batch_size=1024,\n",
    "                input_size=(224, 224, 3),\n",
    "                augmenter:ImageDataGenerator=None,\n",
    "                shuffle=False,\n",
    "                seed=42,\n",
    "                amount_augmented=2,\n",
    "                do_multiply=False,\n",
    "                do_augment=False,\n",
    "                ret_labels=True,\n",
    "                random=False\n",
    "               ):\n",
    "        \n",
    "    self.df = multiply_df(amount_augmented, df) if do_multiply else df\n",
    "    self.batch_size = batch_size\n",
    "    self.input_size = input_size\n",
    "    self.shuffle = shuffle\n",
    "    self.seed = seed\n",
    "    self.do_augment = do_augment\n",
    "    self.augmenter:ImageDataGenerator = augmenter\n",
    "    self.amount_augmented = amount_augmented\n",
    "    self.ret_labels = ret_labels\n",
    "    self.random = random\n",
    "\n",
    "    self.n = len(self.df)\n",
    "\n",
    "  # GB = 1024**3\n",
    "  #@lru_cache(use_memory_up_to=(leave_free_GB * 1024**3))\n",
    "  #def __load_image(self, image_index):\n",
    "  #  path = f\"food/{str(image_index).zfill(5)}.jpg\"\n",
    "  #  h, w, chann = self.input_size\n",
    "  #  img = image.load_img(path, target_size=(h, w))\n",
    "  #  img = image.img_to_array(img)\n",
    "  #  return img\n",
    "\n",
    "  def __get_image_batch(self, img_indices):\n",
    "    batch = [imageDict[x] for _, x in img_indices.iteritems()]\n",
    "    batch = np.stack( batch, axis=0 )\n",
    "    return batch\n",
    "\n",
    "  def __get_transform(self, img_batch):\n",
    "    # returns the transformed img_batch if augmenter defined\n",
    "    # TODO check if the random_transform returns a copy or else \n",
    "    # use https://stackoverflow.com/questions/54909357/how-to-get-functools-lru-cache-to-return-new-instances\n",
    "    # to return copy of load_img\n",
    "    # TODO self seed probably does not do it here! , seed=self.seed\n",
    "    #img_batch = [self.augmenter.random_transform(img, seed=self.seed) for img in img_batch], axis=0 )\n",
    "    if self.do_augment:\n",
    "    #    img_batch = pool.map(self.augmenter.random_transform, img_batch)\n",
    "    #    img_batch = np.stack(img_batch, axis=0)\n",
    "        for i, img in enumerate(img_batch):\n",
    "            img_batch[i] = self.augmenter.random_transform(img, seed=self.seed)\n",
    "    img_batch = self.augmenter.standardize(img_batch)\n",
    "    return img_batch\n",
    "\n",
    "  def __get_data(self, batch_df):\n",
    "    \n",
    "    # batch_df is of form [A, B, C, y, transform_n] x n\n",
    "    batch_A = self.__get_image_batch(batch_df['A'])\n",
    "    batch_B = self.__get_image_batch(batch_df['B'])\n",
    "    batch_C = self.__get_image_batch(batch_df['C'])\n",
    "    #show_images(batch_A)\n",
    "    batch_A = self.__get_transform(batch_A)\n",
    "    #show_images(batch_A)\n",
    "    batch_B = self.__get_transform(batch_B)\n",
    "    batch_C = self.__get_transform(batch_C)\n",
    "    X = [batch_A, batch_B, batch_C]\n",
    "    y = batch_df['y'].to_numpy() if self.ret_labels else []\n",
    "    y = y if not self.random else np.random.randint(1, size=(1,3,batch_df.shape[0])).T\n",
    "    return X, y\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    if self.shuffle:\n",
    "      self.df = self.df.sample(frac=1, random_state=self.seed).reset_index(drop=True)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "    X, y = self.__get_data(batches)\n",
    "    return X, y\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.n // self.batch_size\n",
    "\n",
    "testDG = task4DataGenerator(train_split, batch_size=2, augmenter=trainAug)\n",
    "X, y = testDG[0]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HwIijdHWBuIi"
   },
   "outputs": [],
   "source": [
    "trainGN = task4DataGenerator(train_split, do_augment=True, do_multiply=True, \n",
    "                             augmenter=trainAug, batch_size=BATCH_SIZE_IM,\n",
    "                            shuffle=True, random=True)\n",
    "valGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE_IM, random=True)\n",
    "# let's use the public score as test actually\n",
    "#testGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_reversed = train_split.copy()\n",
    "train_split_reversed[\"A\"] = train_split[\"B\"].copy()\n",
    "train_split_reversed[\"B\"] = train_split[\"A\"].copy()\n",
    "trainGNrev = task4DataGenerator(train_split_reversed, do_augment=True, do_multiply=True, \n",
    "                             augmenter=trainAug, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ6SEW3LyRdg"
   },
   "source": [
    "Let's try to follow [this](https://www.pyimagesearch.com/2020/04/27/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning/) example and [this](https://github.com/noelcodella/tripletloss-keras-tensorflow/blob/master/tripletloss.py) for triplet loss for a bit in regards to fine tuning the ResNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(_, y_pred):\n",
    "    #print(y_pred.shape)\n",
    "    margin = K.constant(1)\n",
    "    return K.mean(K.maximum(K.constant(0), K.square(y_pred[:,0,0]) - 0.5*(K.square(y_pred[:,1,0])+K.square(y_pred[:,2,0])) + margin))\n",
    "\n",
    "def accuracy(_, y_pred):\n",
    "    #print(y_true.shape)\n",
    "    return K.mean(y_pred[:,0,0] < y_pred[:,1,0])\n",
    "\n",
    "def l2Norm(x):\n",
    "    return  K.l2_normalize(x, axis=-1)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "hPuVKCpbAH5S"
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "#tboard_callback = keras.callbacks.TensorBoard(log_dir = logs, update_freq=50)\n",
    "tboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir = logs,\n",
    "    histogram_freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripletCheckpoint_filepath = 'tripletCheckpoint/'\n",
    "model_tripletCheckpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=tripletCheckpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(emb_size):\n",
    "    input_shape=(224, 224, 3)\n",
    "    \n",
    "    # Initialize a ResNet50_ImageNet Model\n",
    "    resnet_input = Input(shape=input_shape)\n",
    "    resnet_model = keras.applications.resnet50.ResNet50(weights='imagenet', include_top = False, input_tensor=resnet_input)\n",
    "\n",
    "    # New Layers over ResNet50\n",
    "    net = resnet_model.output\n",
    "    #net = kl.Flatten(name='flatten')(net)\n",
    "    net = GlobalAveragePooling2D(name='gap')(net)\n",
    "    #net = kl.Dropout(0.5)(net)\n",
    "    net = Dense(emb_size,activation='relu',name='t_emb_1')(net)\n",
    "    net = Lambda(lambda  x: K.l2_normalize(x,axis=1), name='t_emb_1_l2norm')(net)\n",
    "\n",
    "    # model creation\n",
    "    base_model = Model(resnet_model.input, net, name=\"base_model\")\n",
    "\n",
    "    # triplet framework, shared weights\n",
    "    input_anchor = Input(shape=input_shape, name='input_anchor')\n",
    "    input_positive = Input(shape=input_shape, name='input_pos')\n",
    "    input_negative = Input(shape=input_shape, name='input_neg')\n",
    "\n",
    "    net_anchor = base_model(input_anchor)\n",
    "    net_positive = base_model(input_positive)\n",
    "    net_negative = base_model(input_negative)\n",
    "\n",
    "    # The Lamda layer produces output using given function. Here its Euclidean distance.\n",
    "    positive_dist = Lambda(euclidean_distance, name='pos_dist')([net_anchor, net_positive])\n",
    "    negative_dist = Lambda(euclidean_distance, name='neg_dist')([net_anchor, net_negative])\n",
    "    tertiary_dist = Lambda(euclidean_distance, name='ter_dist')([net_positive, net_negative])\n",
    "\n",
    "    # This lambda layer simply stacks outputs so both distances are available to the objective\n",
    "    stacked_dists = Lambda(lambda vects: K.stack(vects, axis=1), name='stacked_dists')([positive_dist, negative_dist, tertiary_dist])\n",
    "\n",
    "    model = Model([input_anchor, input_positive, input_negative], stacked_dists, name='triple_siamese')\n",
    "\n",
    "    base_lr = 0.0001\n",
    "    momentum = 0.9\n",
    "    model.compile(\n",
    "      #optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      optimizer=keras.optimizers.SGD(learning_rate=base_lr, momentum=momentum, nesterov=False, name=\"SGD\"),\n",
    "      loss=triplet_loss,\n",
    "      metrics=[accuracy])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "TMyNuFaxg54M",
    "outputId": "9f5cc07f-7cb9-495f-8a29-adae0e7a2da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 4s 0us/step\n",
      "Model: \"triple_siamese\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_anchor (InputLayer)       [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_pos (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_neg (InputLayer)          [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         (None, 256)          24112256    input_anchor[0][0]               \n",
      "                                                                 input_pos[0][0]                  \n",
      "                                                                 input_neg[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pos_dist (Lambda)               (None, 1)            0           base_model[0][0]                 \n",
      "                                                                 base_model[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "neg_dist (Lambda)               (None, 1)            0           base_model[0][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ter_dist (Lambda)               (None, 1)            0           base_model[1][0]                 \n",
      "                                                                 base_model[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "stacked_dists (Lambda)          (None, 3, 1)         0           pos_dist[0][0]                   \n",
      "                                                                 neg_dist[0][0]                   \n",
      "                                                                 ter_dist[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,112,256\n",
      "Trainable params: 24,059,136\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "createModel(EMB_SIZE).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel(EMB_SIZE)\n",
    "model.load_weights(tripletCheckpoint_filepath)\n",
    "print(\"Starting to fit\")\n",
    "fitted = model.fit(\n",
    "    trainGN,\n",
    "    batch_size=BATCH_SIZE_IM,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stopping, tboard_callback, model_tripletCheckpoint_callback],\n",
    "    validation_data=valGN,\n",
    "    use_multiprocessing = True,\n",
    "    workers=8,\n",
    "    verbose=1)\n",
    "print(\"Done fitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving model ...')\n",
    "output = \"embeddingModel\"\n",
    "\n",
    "# Save the model and weights\n",
    "model.save(f'{output}.h5')\n",
    "\n",
    "# Due to some remaining Keras bugs around loading custom optimizers\n",
    "# and objectives, we save the model architecture as well\n",
    "model_json = model.to_json()\n",
    "with open(f'{output}.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we now have the \"trained\" embedding, let's try a Ridge regression onto the labels we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBaseModelFromFile(path):\n",
    "    with open(path + '.json', \"r\") as json_file:\n",
    "        model_json = json_file.read()\n",
    "\n",
    "        loaded_model = keras.models.model_from_json(model_json)\n",
    "        loaded_model.load_weights(path + '.h5')\n",
    "        return loaded_model.get_layer('base_model')\n",
    "\n",
    "#baseModel = loadBaseModelFromFile(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(base_model_path=\"embeddingModel\", metrics=METRICS):\n",
    "    #baseModel = None\n",
    "    base_model = loadBaseModelFromFile(base_model_path)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    input_A = Input(shape=(224, 224, 3), name='input_A')\n",
    "    input_B = Input(shape=(224, 224, 3), name='input_B')\n",
    "    input_C = Input(shape=(224, 224, 3), name='input_C')\n",
    "\n",
    "    # create a new model without the triple loss\n",
    "    model_A = base_model(input_A)\n",
    "    model_B = base_model(input_B)\n",
    "    model_C = base_model(input_C)\n",
    "    #model = Model(input_single, net_single, name='embedding_net')\n",
    "\n",
    "   \n",
    "\n",
    "    # we use 3 times base model to get the features from the 3 images combined\n",
    "    concat = Concatenate()([model_A, model_B, model_C])\n",
    "    headModel = Dropout(0.3)(concat)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.3)(headModel)\n",
    "    headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.3)(headModel)\n",
    "    headModel = Dense(1, activation='sigmoid')(headModel)\n",
    "    model = Model(inputs=[input_A, input_B, input_C], outputs=[headModel], name=\"classifier_net\")\n",
    "\n",
    "    # actually compile it now\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.binary_crossentropy,\n",
    "      metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classifier_net\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_A (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_B (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_C (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         (None, 256)          24112256    input_A[0][0]                    \n",
      "                                                                 input_B[0][0]                    \n",
      "                                                                 input_C[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 768)          0           base_model[3][0]                 \n",
      "                                                                 base_model[4][0]                 \n",
      "                                                                 base_model[5][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          196864      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,375,169\n",
      "Trainable params: 262,913\n",
      "Non-trainable params: 24,112,256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "make_model(\"embeddingModel\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoint/'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2762</td>\n",
       "      <td>3127</td>\n",
       "      <td>1659</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1531</td>\n",
       "      <td>62</td>\n",
       "      <td>3849</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1514</td>\n",
       "      <td>1885</td>\n",
       "      <td>373</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601</td>\n",
       "      <td>4295</td>\n",
       "      <td>845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1306</td>\n",
       "      <td>3411</td>\n",
       "      <td>4212</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238055</th>\n",
       "      <td>3177</td>\n",
       "      <td>1791</td>\n",
       "      <td>1130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238056</th>\n",
       "      <td>714</td>\n",
       "      <td>1913</td>\n",
       "      <td>3094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238057</th>\n",
       "      <td>2801</td>\n",
       "      <td>62</td>\n",
       "      <td>1828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238058</th>\n",
       "      <td>709</td>\n",
       "      <td>1363</td>\n",
       "      <td>1010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238059</th>\n",
       "      <td>4385</td>\n",
       "      <td>665</td>\n",
       "      <td>966</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y\n",
       "0       2762  3127  1659  0.0\n",
       "1       1531    62  3849  1.0\n",
       "2       1514  1885   373  1.0\n",
       "3       2601  4295   845  1.0\n",
       "4       1306  3411  4212  1.0\n",
       "...      ...   ...   ...  ...\n",
       "238055  3177  1791  1130  1.0\n",
       "238056   714  1913  3094  0.0\n",
       "238057  2801    62  1828  1.0\n",
       "238058   709  1363  1010  1.0\n",
       "238059  4385   665   966  1.0\n",
       "\n",
       "[238060 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPD = pd.read_csv(\"train_triplets.txt\", header=None, delimiter=' ')\n",
    "# Add the y lable, where 1 means exactly what the exercise defines,\n",
    "# i.e. 0 is closer in taste to 1 than 2\n",
    "trainPDreverse = trainPD.copy()\n",
    "trainPDreverse[1] = trainPD[2].copy()\n",
    "trainPDreverse[2] = trainPD[1].copy()\n",
    "trainPD['y'] = pd.DataFrame(np.ones((trainPD.shape[0],1)), columns=[\"y\"])\n",
    "trainPDreverse['y'] = pd.DataFrame(np.zeros((trainPDreverse.shape[0],1)), columns=[\"y\"])\n",
    "trainPD = trainPD.append(trainPDreverse).reset_index(drop=True)\n",
    "# move B to A -> same lable, but a should make for more diverse input with same idea behind it\n",
    "trainPDreverseF = trainPD.copy()\n",
    "trainPDreverseF[0] = trainPD[1].copy()\n",
    "trainPDreverseF[1] = trainPD[0].copy()\n",
    "trainPD = trainPD.append(trainPDreverseF).reset_index(drop=True)\n",
    "# Give labels and reshuffle\n",
    "trainPD.columns = ['A', 'B', 'C', 'y']\n",
    "trainPD = trainPD.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "trainPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "createTrainSplit(trainPD)\n",
    "trainGN = task4DataGenerator(train_split, do_augment=True, \n",
    "                             augmenter=trainAug, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "valGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model\n",
      "Starting to fit\n",
      "Epoch 1/10\n",
      "  95/1766 [>.............................] - ETA: 26:21 - loss: 0.4350 - tp: 8438.0000 - fp: 2359.0000 - tn: 9679.0000 - fn: 3460.0000 - accuracy: 0.7569 - precision: 0.7815 - recall: 0.7092 - auc: 0.8368 - prc: 0.8398"
     ]
    }
   ],
   "source": [
    "print(\"Making model\")\n",
    "model = make_model()\n",
    "model.load_weights(checkpoint_filepath)\n",
    "print(\"Starting to fit\")\n",
    "fitted = model.fit(\n",
    "    trainGN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=4,\n",
    "    callbacks=[early_stopping, tboard_callback],\n",
    "    validation_data=valGN,\n",
    "    #use_multiprocessing = True,\n",
    "    workers=6,\n",
    "    verbose=1)\n",
    "print(\"Done fitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually create the output for the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPD.columns = ['A', 'B', 'C']\n",
    "submissionGN = task4DataGenerator(testPD, augmenter=valAug, batch_size=8, ret_labels=False)\n",
    "testPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = make_model()\n",
    "test.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test.predict(submissionGN, verbose=1, use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res)\n",
    "res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks strongly like my model has no idea what to do with half of the inputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Change shape and threshold to 0 1 for submission')\n",
    "seq_predictions=np.transpose(res.to_numpy())[0]  # transformation to get (n,)\n",
    "print(seq_predictions.shape)  # now the shape is (n,)\n",
    "# Applying transformation to get binary values predictions with 0.5 as thresold\n",
    "seq_predictions = list(map(lambda x: 0 if x<0.5 else 1, seq_predictions))\n",
    "seq_predictions = pd.DataFrame(seq_predictions)\n",
    "seq_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvyuMd0XbWu6"
   },
   "outputs": [],
   "source": [
    "seq_predictions.to_csv(\"out.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQLKF5XjVpfGVnyYGIq1JW",
   "name": "Task4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
