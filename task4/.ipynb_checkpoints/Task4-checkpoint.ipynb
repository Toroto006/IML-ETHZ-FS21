{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwCJDlDblbfn"
   },
   "source": [
    "### Trying to solve Task 4 now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oeL297NoB-yf"
   },
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.4)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.8.0-cp36-cp36m-manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 124.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (8.2.0)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 123.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 123.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 127.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=419e823a1ee099df6fd7ca442b3e035d2a7d8e5ab0d42f61a58138573c76c178\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: scipy, threadpoolctl, joblib, scikit-learn, sklearn, psutil, pytz, pandas\n",
      "Successfully installed joblib-1.0.1 pandas-1.1.5 psutil-5.8.0 pytz-2021.1 scikit-learn-0.24.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn numpy matplotlib psutil pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard_plugin_profile\n",
      "  Downloading tensorboard_plugin_profile-2.4.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (56.2.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (3.17.0)\n",
      "Collecting gviz-api>=1.9.0\n",
      "  Downloading gviz_api-1.9.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from werkzeug>=0.11.15->tensorboard_plugin_profile) (0.8)\n",
      "Installing collected packages: gviz-api, tensorboard-plugin-profile\n",
      "Successfully installed gviz-api-1.9.0 tensorboard-plugin-profile-2.4.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorboard_plugin_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3fa398f5e2750c46\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3fa398f5e2750c46\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/ --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "oehqk2wZPnlF",
    "outputId": "42abd04d-aed9-4c82-9bfa-55ead3b93fd7"
   },
   "outputs": [],
   "source": [
    "# run for a remote notebook: docker run -it --gpus all -v /root/iml2021/task4:/tf/task4 -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter\n",
    "# need stuff cd /task4 && python -m pip install sklearn numpy matplotlib psutil pandas && python3 task4.py\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "#from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from lru_cache_memory_aware import lru_cache\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW_pdKJmXr1R"
   },
   "source": [
    "Following is the example by keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cSG9RinbUd5M"
   },
   "outputs": [],
   "source": [
    "# TODO https://keras.io/api/applications/resnet/ use ResNet50v2 and then one last time ResNet152v2\n",
    "def example():\n",
    "  model = ResNet50(\n",
    "      include_top=True,\n",
    "      weights=\"imagenet\",\n",
    "      input_tensor=None,\n",
    "      input_shape=None,\n",
    "      pooling=None,\n",
    "      classes=1000,\n",
    "      classifier_activation=\"softmax\",\n",
    "  )\n",
    "  img_path = 'food/00000.jpg'\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "\n",
    "  preds = model.predict(x)\n",
    "  # decode the results into a list of tuples (class, description, probability)\n",
    "  # (one such list for each sample in the batch)\n",
    "  print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MwoeX2dz9hu-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip -o food.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "hk0UmvvRcLFY",
    "outputId": "201a00bf-ece3-4b94-e7bb-44d0544b8a67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2762</td>\n",
       "      <td>3127</td>\n",
       "      <td>1659</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1531</td>\n",
       "      <td>62</td>\n",
       "      <td>3849</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1514</td>\n",
       "      <td>1885</td>\n",
       "      <td>373</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2601</td>\n",
       "      <td>4295</td>\n",
       "      <td>845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1306</td>\n",
       "      <td>3411</td>\n",
       "      <td>4212</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238055</th>\n",
       "      <td>3177</td>\n",
       "      <td>1791</td>\n",
       "      <td>1130</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238056</th>\n",
       "      <td>714</td>\n",
       "      <td>1913</td>\n",
       "      <td>3094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238057</th>\n",
       "      <td>2801</td>\n",
       "      <td>62</td>\n",
       "      <td>1828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238058</th>\n",
       "      <td>709</td>\n",
       "      <td>1363</td>\n",
       "      <td>1010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238059</th>\n",
       "      <td>4385</td>\n",
       "      <td>665</td>\n",
       "      <td>966</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y\n",
       "0       2762  3127  1659  0.0\n",
       "1       1531    62  3849  1.0\n",
       "2       1514  1885   373  1.0\n",
       "3       2601  4295   845  1.0\n",
       "4       1306  3411  4212  1.0\n",
       "...      ...   ...   ...  ...\n",
       "238055  3177  1791  1130  1.0\n",
       "238056   714  1913  3094  0.0\n",
       "238057  2801    62  1828  1.0\n",
       "238058   709  1363  1010  1.0\n",
       "238059  4385   665   966  1.0\n",
       "\n",
       "[238060 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPD = pd.read_csv(\"train_triplets.txt\", header=None, delimiter=' ')\n",
    "testPD = pd.read_csv(\"test_triplets.txt\", header=None, delimiter=' ')\n",
    "# Add the y lable, where 1 means exactly what the exercise defines,\n",
    "# i.e. 0 is closer in taste to 1 than 2\n",
    "trainPDreverse = trainPD.copy()\n",
    "trainPDreverse[1] = trainPD[2].copy()\n",
    "trainPDreverse[2] = trainPD[1].copy()\n",
    "trainPD['y'] = pd.DataFrame(np.ones((trainPD.shape[0],1)), columns=[\"y\"])\n",
    "trainPDreverse['y'] = pd.DataFrame(np.zeros((trainPDreverse.shape[0],1)), columns=[\"y\"])\n",
    "trainPD = trainPD.append(trainPDreverse).reset_index(drop=True)\n",
    "# TODO move B to A -> same lable, but a should make for more diverse input with same idea behind it\n",
    "trainPDreverseF = trainPD.copy()\n",
    "trainPDreverseF[0] = trainPD[1].copy()\n",
    "trainPDreverseF[1] = trainPD[0].copy()\n",
    "trainPD = trainPD.append(trainPDreverseF).reset_index(drop=True)\n",
    "# Give labels and reshuffle\n",
    "trainPD.columns = ['A', 'B', 'C', 'y']\n",
    "trainPD = trainPD.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "trainPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJddS7B4ui7F"
   },
   "source": [
    "Prepare the data splits  \n",
    "TODO: create the generator with turning and then combine the correct 3 always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "wFOw0IBJt6aa",
    "outputId": "acd9c173-80d6-4bcd-d767-b0e0ab4d105f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214254, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60764</th>\n",
       "      <td>2640</td>\n",
       "      <td>3419</td>\n",
       "      <td>4488</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103755</th>\n",
       "      <td>4877</td>\n",
       "      <td>851</td>\n",
       "      <td>2256</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y\n",
       "60764   2640  3419  4488  0.0\n",
       "103755  4877   851  2256  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split picture combinations\n",
    "def createTrainSplit(df):\n",
    "  global train_split, test_split, val_split\n",
    "  train_split, test_split = train_test_split(df, test_size=0.1, random_state=random_state)\n",
    "  #train_split, val_split = train_test_split(train_split, test_size=0.2, random_state=random_state)\n",
    "\n",
    "createTrainSplit(trainPD)\n",
    "print(train_split.shape)\n",
    "train_split.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FDsZxP7E0rH"
   },
   "source": [
    "Let's do the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "joY6BRUTEz3m"
   },
   "outputs": [],
   "source": [
    "# TODO maybe think if actually using resnet preprocess_input is ok\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "# initialize the validation/testing data augmentation object (which\n",
    "# we'll be adding mean subtraction to)\n",
    "valAug = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCBINL80LUgK"
   },
   "source": [
    "SHIT we have to write our own generator because of the different input... [example](https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7eq6Zs-vCZBg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>y</th>\n",
       "      <th>transform_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2640</td>\n",
       "      <td>3419</td>\n",
       "      <td>4488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2640</td>\n",
       "      <td>3419</td>\n",
       "      <td>4488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4877</td>\n",
       "      <td>851</td>\n",
       "      <td>2256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4877</td>\n",
       "      <td>851</td>\n",
       "      <td>2256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4068</td>\n",
       "      <td>367</td>\n",
       "      <td>1567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428503</th>\n",
       "      <td>969</td>\n",
       "      <td>720</td>\n",
       "      <td>191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428504</th>\n",
       "      <td>3243</td>\n",
       "      <td>4276</td>\n",
       "      <td>3461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428505</th>\n",
       "      <td>3243</td>\n",
       "      <td>4276</td>\n",
       "      <td>3461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428506</th>\n",
       "      <td>2881</td>\n",
       "      <td>4180</td>\n",
       "      <td>3300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428507</th>\n",
       "      <td>2881</td>\n",
       "      <td>4180</td>\n",
       "      <td>3300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428508 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A     B     C    y  transform_n\n",
       "0       2640  3419  4488  0.0            0\n",
       "1       2640  3419  4488  0.0            1\n",
       "2       4877   851  2256  0.0            0\n",
       "3       4877   851  2256  0.0            1\n",
       "4       4068   367  1567  1.0            0\n",
       "...      ...   ...   ...  ...          ...\n",
       "428503   969   720   191  0.0            1\n",
       "428504  3243  4276  3461  1.0            0\n",
       "428505  3243  4276  3461  1.0            1\n",
       "428506  2881  4180  3300  1.0            0\n",
       "428507  2881  4180  3300  1.0            1\n",
       "\n",
       "[428508 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply_df(amount, df:pd.DataFrame):\n",
    "  ret = df.copy()\n",
    "  ret = ret.apply(lambda row: row.loc[row.index.repeat(amount)], axis=0).reset_index(drop=True)\n",
    "  # now add the transform_n just to see in index afterwards\n",
    "  ns = np.concatenate(list(itertools.repeat(np.arange(0,amount), df.shape[0])))\n",
    "  ret[\"transform_n\"] = pd.DataFrame(ns,columns=[\"transform_n\"])\n",
    "  return ret\n",
    "\n",
    "multiply_df(2, train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "x77kcv4UFz1e"
   },
   "outputs": [],
   "source": [
    "def show_images(images: [np.ndarray]) -> None:\n",
    "    n: int = len(images)\n",
    "    f = plt.figure()\n",
    "    for i in range(n):\n",
    "        # Debug, plot figure\n",
    "        f.add_subplot(1, n, i + 1)\n",
    "        plt.imshow(image.array_to_img(images[i]))\n",
    "\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_index):\n",
    "    path = f\"food/{str(image_index).zfill(5)}.jpg\"\n",
    "    h, w, = (224, 224)\n",
    "    img = image.load_img(path, target_size=(h, w))\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "imageDict = {}\n",
    "for i in range(0, 10000):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    imageDict[i] = load_image(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cpus = multiprocessing.cpu_count()\n",
    "except NotImplementedError:\n",
    "    cpus = 2   # arbitrary default\n",
    "pool = multiprocessing.Pool(processes=cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y1VoR1bkLfGU"
   },
   "outputs": [],
   "source": [
    "class task4DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "  def __init__(self, df,\n",
    "                batch_size=1024,\n",
    "                input_size=(224, 224, 3),\n",
    "                augmenter:ImageDataGenerator=None,\n",
    "                shuffle=False,\n",
    "                seed=42,\n",
    "                amount_augmented=1,\n",
    "                do_multiply=False,\n",
    "                do_augment=False,\n",
    "                ret_labels=True\n",
    "               ):\n",
    "        \n",
    "    self.df = multiply_df(amount_augmented, df) if do_multiply else df\n",
    "    self.batch_size = batch_size\n",
    "    self.input_size = input_size\n",
    "    self.shuffle = shuffle\n",
    "    self.seed = seed\n",
    "    self.do_augment = do_augment\n",
    "    self.augmenter:ImageDataGenerator = augmenter\n",
    "    self.amount_augmented = amount_augmented\n",
    "    self.ret_labels = ret_labels\n",
    "\n",
    "    self.n = len(self.df)\n",
    "\n",
    "  # GB = 1024**3\n",
    "  #@lru_cache(use_memory_up_to=(leave_free_GB * 1024**3))\n",
    "  #def __load_image(self, image_index):\n",
    "  #  path = f\"food/{str(image_index).zfill(5)}.jpg\"\n",
    "  #  h, w, chann = self.input_size\n",
    "  #  img = image.load_img(path, target_size=(h, w))\n",
    "  #  img = image.img_to_array(img)\n",
    "  #  return img\n",
    "\n",
    "  def __get_image_batch(self, img_indices):\n",
    "    batch = [imageDict[x] for _, x in img_indices.iteritems()]\n",
    "    batch = np.stack( batch, axis=0 )\n",
    "    return batch\n",
    "\n",
    "  def __get_transform(self, img_batch):\n",
    "    # returns the transformed img_batch if augmenter defined\n",
    "    # TODO check if the random_transform returns a copy or else \n",
    "    # use https://stackoverflow.com/questions/54909357/how-to-get-functools-lru-cache-to-return-new-instances\n",
    "    # to return copy of load_img\n",
    "    # TODO self seed probably does not do it here! , seed=self.seed\n",
    "    #img_batch = [self.augmenter.random_transform(img, seed=self.seed) for img in img_batch], axis=0 )\n",
    "    if self.do_augment:\n",
    "    #    img_batch = pool.map(self.augmenter.random_transform, img_batch)\n",
    "    #    img_batch = np.stack(img_batch, axis=0)\n",
    "        for i, img in enumerate(img_batch):\n",
    "            img_batch[i] = self.augmenter.random_transform(img, seed=self.seed)\n",
    "    img_batch = self.augmenter.standardize(img_batch)\n",
    "    return img_batch\n",
    "\n",
    "  def __get_data(self, batch_df):\n",
    "    \n",
    "    # batch_df is of form [A, B, C, y, transform_n] x n\n",
    "    batch_A = self.__get_image_batch(batch_df['A'])\n",
    "    batch_B = self.__get_image_batch(batch_df['B'])\n",
    "    batch_C = self.__get_image_batch(batch_df['C'])\n",
    "    #show_images(batch_A)\n",
    "    batch_A = self.__get_transform(batch_A)\n",
    "    #show_images(batch_A)\n",
    "    batch_B = self.__get_transform(batch_B)\n",
    "    batch_C = self.__get_transform(batch_C)\n",
    "    X = [batch_A, batch_B, batch_C]\n",
    "    y = batch_df['y'].to_numpy() if self.ret_labels else []\n",
    "    return X, y\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    if self.shuffle:\n",
    "      self.df = self.df.sample(frac=1, random_state=self.seed).reset_index(drop=True)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "    X, y = self.__get_data(batches)\n",
    "    return X, y\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.n // self.batch_size\n",
    "\n",
    "testDG = task4DataGenerator(train_split, batch_size=2, augmenter=trainAug)\n",
    "X, y = testDG[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HwIijdHWBuIi"
   },
   "outputs": [],
   "source": [
    "trainGN = task4DataGenerator(train_split, do_augment=True, do_multiply=True, \n",
    "                             augmenter=trainAug, batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "valGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE)\n",
    "# let's use the public score as test actually\n",
    "#testGN = task4DataGenerator(test_split, augmenter=valAug, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ6SEW3LyRdg"
   },
   "source": [
    "Let's try to follow [this](https://www.pyimagesearch.com/2020/04/27/fine-tuning-resnet-with-keras-tensorflow-and-deep-learning/) example for a bit in regards to fine tuning the ResNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gT8hPGpttumv"
   },
   "outputs": [],
   "source": [
    "# TODO https://keras.io/api/applications/resnet/ use ResNet50v2 and then one last time ResNet152v2\n",
    "def getBaseModelRN50(input_shape=(224, 224, 3)):\n",
    "  # ImageNet trained ResNet50\n",
    "  baseModel = ResNet50(\n",
    "      include_top=False,\n",
    "      weights=\"imagenet\",\n",
    "      input_tensor=None,\n",
    "      input_shape=input_shape,\n",
    "      pooling=None,\n",
    "      classifier_activation=\"softmax\",\n",
    "  )\n",
    "  for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "  return baseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_No7pa4cgpVz"
   },
   "outputs": [],
   "source": [
    "def getMobileNet(input_shape=(224, 224, 3)):\n",
    "  baseModel = MobileNet(\n",
    "    input_shape=input_shape,\n",
    "    alpha=1.0,\n",
    "    depth_multiplier=1,\n",
    "    dropout=0.001,\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classifier_activation=\"softmax\")\n",
    "  for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "  return baseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wsgZpy_e8CIW"
   },
   "outputs": [],
   "source": [
    "def getSingleImgModel50(baseModel, inp):\n",
    "  # The following builds a new head for the baseModel to get the flatten\n",
    "  headModel = baseModel(inp)\n",
    "  #headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "  headModel = AveragePooling2D(pool_size=(4, 4))(headModel) # upper or this\n",
    "  headModel = Flatten(name=\"flatten\")(headModel)\n",
    "  #headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "  # place the head model on top of the base model (this will become\n",
    "  # the model for each picture we use)\n",
    "  return Model(inputs=inp, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YQWrpaXe533B"
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  #baseModel = None\n",
    "  baseModel = getBaseModelRN50()\n",
    "  input_A = keras.Input(shape=(224, 224, 3), name='input_A')\n",
    "  input_B = keras.Input(shape=(224, 224, 3), name='input_B')\n",
    "  input_C = keras.Input(shape=(224, 224, 3), name='input_C')\n",
    "  modelA = getSingleImgModel50(baseModel, input_A)\n",
    "  modelB = getSingleImgModel50(baseModel, input_B)\n",
    "  modelC = getSingleImgModel50(baseModel, input_C)\n",
    "  #Fix layer naming as otherwise we have colissions\n",
    "  for layer in modelA.layers :\n",
    "    if \"input\" not in layer._name:\n",
    "        layer._name = layer.name + str('_A')\n",
    "  for layer in modelB.layers :\n",
    "    if \"input\" not in layer._name:\n",
    "        layer._name = layer.name + str('_B')\n",
    "  for layer in modelC.layers :\n",
    "    if \"input\" not in layer._name:\n",
    "        layer._name = layer.name + str('_C')\n",
    "\n",
    "  # we use 3 times ImageNet to get the features from the 3 images combined\n",
    "  concat = Concatenate()([modelA.outputs[0], modelB.outputs[0], modelC.outputs[0]])\n",
    "  headModel = Dropout(0.5)(concat)\n",
    "  headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "  headModel = Dropout(0.5)(headModel)\n",
    "  headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "  headModel = Dropout(0.5)(headModel)\n",
    "  #headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "  #headModel = Dropout(0.5)(headModel)\n",
    "  #headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "  #headModel = Dropout(0.25)(headModel)\n",
    "  headModel = Dense(1, activation='sigmoid')(headModel)\n",
    "  # try https://github.com/noelcodella/tripletloss-keras-tensorflow/blob/master/tripletloss.py\n",
    "  model = Model(inputs=[input_A, input_B, input_C], outputs=[headModel])\n",
    "\n",
    "  # actually compile it now\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=keras.losses.binary_crossentropy,\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "TMyNuFaxg54M",
    "outputId": "9f5cc07f-7cb9-495f-8a29-adae0e7a2da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 3s 0us/step\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_A (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_B (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_C (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "resnet50_A_B_C (Functional)     (None, 7, 7, 2048)   23587712    input_A[0][0]                    \n",
      "                                                                 input_B[0][0]                    \n",
      "                                                                 input_C[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_A (AveragePoo (None, 1, 1, 2048)   0           resnet50_A_B_C[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1_B (AverageP (None, 1, 1, 2048)   0           resnet50_A_B_C[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2_C (AverageP (None, 1, 1, 2048)   0           resnet50_A_B_C[2][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_A (Flatten)             (None, 2048)         0           average_pooling2d_A[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_B (Flatten)             (None, 2048)         0           average_pooling2d_1_B[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_C (Flatten)             (None, 2048)         0           average_pooling2d_2_C[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6144)         0           flatten_A[0][0]                  \n",
      "                                                                 flatten_B[0][0]                  \n",
      "                                                                 flatten_C[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 6144)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          3146240     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            513         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 26,997,121\n",
      "Trainable params: 3,409,409\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "make_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hPuVKCpbAH5S"
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "#tboard_callback = keras.callbacks.TensorBoard(log_dir = logs, update_freq=50)\n",
    "tboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir = logs,\n",
    "    histogram_freq = 1,\n",
    "    profile_batch=(10,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoint/'\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "1UaZienz__oe",
    "outputId": "61249214-22d4-42c1-b0a6-34c3e20a53cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model\n",
      "Starting to fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2678/2678 [==============================] - 3341s 1s/step - loss: 0.6925 - tp: 45163.0000 - fp: 34968.0000 - tn: 136100.0000 - fn: 126553.0000 - accuracy: 0.5288 - precision: 0.5636 - recall: 0.2630 - auc: 0.5342 - prc: 0.5515 - val_loss: 0.6782 - val_tp: 5868.0000 - val_fp: 2644.0000 - val_tn: 18867.0000 - val_fn: 15373.0000 - val_accuracy: 0.5786 - val_precision: 0.6894 - val_recall: 0.2763 - val_auc: 0.5842 - val_prc: 0.6187\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57857, saving model to checkpoint/\n",
      "Epoch 2/200\n",
      " 416/2678 [===>..........................] - ETA: 44:19 - loss: 0.6819 - tp: 6688.0000 - fp: 3981.0000 - tn: 22651.0000 - fn: 19928.0000 - accuracy: 0.5510 - precision: 0.6269 - recall: 0.2513 - auc: 0.5564 - prc: 0.5816"
     ]
    }
   ],
   "source": [
    "print(\"Making model\")\n",
    "model = make_model()\n",
    "#model.load_weights(checkpoint_filepath)\n",
    "print(\"Starting to fit\")\n",
    "fitted = model.fit(\n",
    "    trainGN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, tboard_callback, model_checkpoint_callback],\n",
    "    validation_data=valGN,\n",
    "    use_multiprocessing = True,\n",
    "    workers=8,\n",
    "    verbose=1)\n",
    "print(\"Done fitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually create the output for the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPD.columns = ['A', 'B', 'C']\n",
    "submissionGN = task4DataGenerator(testPD, augmenter=valAug, batch_size=8, ret_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff9dc6636a0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = make_model()\n",
    "test.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2302/7443 [========>.....................] - ETA: 4:41"
     ]
    }
   ],
   "source": [
    "res = test.predict(submissionGN, verbose=1, use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res)\n",
    "res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks strongly like my model has no idea what to do with half of the inputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Change shape and threshold to 0 1 for submission')\n",
    "seq_predictions=np.transpose(res.to_numpy())[0]  # transformation to get (n,)\n",
    "print(seq_predictions.shape)  # now the shape is (n,)\n",
    "# Applying transformation to get binary values predictions with 0.5 as thresold\n",
    "seq_predictions = list(map(lambda x: 0 if x<0.5 else 1, seq_predictions))\n",
    "seq_predictions = pd.DataFrame(seq_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvyuMd0XbWu6"
   },
   "outputs": [],
   "source": [
    "seq_predictions.to_csv(\"/home/ml/iml/outThreeModel.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQLKF5XjVpfGVnyYGIq1JW",
   "name": "Task4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
